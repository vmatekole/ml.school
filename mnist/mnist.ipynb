{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd2fdf97-bbc6-4973-bdde-db769f3b2585",
   "metadata": {},
   "source": [
    "# Pipeline of Digits\n",
    "\n",
    "This is a starting notebook for solving the \"Pipeline of Digits\" assignment.\n",
    "\n",
    "\n",
    "This notebook was created by [Santiago L. Valdarrama](https://twitter.com/svpino) as part of the [Machine Learning School](https://www.ml.school) program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae06bac-01d0-477e-b9f8-1fdd3ebf3dc7",
   "metadata": {},
   "source": [
    "Let's make sure we are running the latest version of the SakeMaker's SDK. **Restart the notebook** after you upgrade the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505a53a1-babe-4238-ad19-e401a9f0a4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.8/site-packages (21.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scikit-learn==1.3.0 in /usr/local/lib/python3.8/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/site-packages (from scikit-learn==1.3.0) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn==1.3.0) (1.7.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/site-packages (from scikit-learn==1.3.0) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn==1.3.0) (3.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas==1.3.3 in /usr/local/lib/python3.8/site-packages (1.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/site-packages (from pandas==1.3.3) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/site-packages (from pandas==1.3.3) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/site-packages (from pandas==1.3.3) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.3.3) (1.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/site-packages (1.3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib==3.6.0 in /usr/local/lib/python3.8/site-packages (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (1.19.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (4.28.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (8.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib==3.6.0) (1.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -q --upgrade awscli boto3\n",
    "# !pip install -q --upgrade PyYAML==6.0\n",
    "!pip install -q --upgrade sagemaker==2.165.0\n",
    "!pip install pip\n",
    "!pip install scikit-learn==1.3.0\n",
    "!pip install pandas==1.3.3\n",
    "!pip install joblib\n",
    "!pip install matplotlib==3.6.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8736d294-1434-4739-82a3-d0e7414a41bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b96a6d2-3cd1-49ca-8219-8929c93b741d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98619548-6458-4ebd-afcb-547bd2488dae",
   "metadata": {},
   "source": [
    "## Creating the S3 Bucket\n",
    "\n",
    "Let's create an S3 bucket where you will upload all the information generated by the pipeline. Make sure you set `BUCKET` to the name of the bucket you want to use. This name has to be unique.\n",
    "\n",
    "If you want to create a bucket in a region other than `us-east-1`, use this command instead:\n",
    "\n",
    "```\n",
    "!aws s3api create-bucket --bucket $BUCKET --create-bucket-configuration LocationConstraint=$region\n",
    "```\n",
    "\n",
    "The `LocationConstraint` argument should specify the region where you want to create the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3ee4d0e-d3a6-4ac3-bd60-e04dd7028ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'vmate-mnist-1'\n",
    "\n",
    "!aws s3api create-bucket --bucket $BUCKET --create-bucket-configuration LocationConstraint=\"eu-north-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3580ab4f-7a15-495d-9fbd-cacb546c9536",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the dataset\n",
    "\n",
    "We have two CSV files containing the MNIST dataset. These files come from the [MNIST in CSV](https://www.kaggle.com/datasets/oddrationale/mnist-in-csv) Kaggle dataset.\n",
    "\n",
    "The `mnist_train.csv` file contains 60,000 training examples and labels. The `mnist_test.csv` contains 10,000 test examples and labels. Each row consists of 785 values: the first value is the label (a number from 0 to 9) and the remaining 784 values are the pixel values (a number from 0 to 255)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf401e-0e1f-4ef8-824a-98e975438054",
   "metadata": {},
   "source": [
    "Let's extract the `dataset.tar.gz` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4210d6-f612-4f7b-9b18-397e2a8ac8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/\n",
      "dataset/mnist_test.csv\n",
      "dataset/mnist_train.csv\n"
     ]
    }
   ],
   "source": [
    "MNIST_FOLDER = Path('mnist')\n",
    "DATASET_FOLDER = Path('dataset')\n",
    "CODE_FOLDER = Path('code')\n",
    "CODE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "sys.path.append('./code')\n",
    "\n",
    "!tar -xvzf dataset.tar.gz --no-same-owner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df65826-f4e1-4683-8bfe-b7889bf8eec9",
   "metadata": {},
   "source": [
    "Let's load the first 10 rows of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a47f00d-c97c-4dde-b588-21c1f3782c12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "5      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "6      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "7      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "8      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "9      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "5      0      0      0      0      0      0      0      0  \n",
       "6      0      0      0      0      0      0      0      0  \n",
       "7      0      0      0      0      0      0      0      0  \n",
       "8      0      0      0      0      0      0      0      0  \n",
       "9      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_FOLDER / 'mnist_train.csv', nrows=10)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a019d1b-4bac-49c5-98bc-ba64174ab084",
   "metadata": {},
   "source": [
    "## S3 upload / locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b66235d0-2ff6-4220-8608-31f0e0ac959f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set S3 location: s3://vmate-mnist-1/mnist/mnist_train.csv\n",
      "Test set S3 location: s3://vmate-mnist-1/mnist/mnist_test.csv\n",
      "Processed set S3 location: ('s3://vmate-mnist-1/mnist/preprocessed_data',)\n"
     ]
    }
   ],
   "source": [
    "S3_LOCATION = f's3://{BUCKET}/{MNIST_FOLDER}'\n",
    "\n",
    "TRAIN_SET_S3_URI = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=str(DATASET_FOLDER / 'mnist_train.csv'), \n",
    "    desired_s3_uri=S3_LOCATION,\n",
    ")\n",
    "\n",
    "TEST_SET_S3_URI = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=str(DATASET_FOLDER / 'mnist_test.csv'), \n",
    "    desired_s3_uri=S3_LOCATION,\n",
    ")\n",
    "\n",
    "PROCESSED_SET_S3_BASE_URI = f'{S3_LOCATION}/preprocessed_data',\n",
    "\n",
    "\n",
    "print(f'Train set S3 location: {TRAIN_SET_S3_URI}')\n",
    "print(f'Test set S3 location: {TEST_SET_S3_URI}')\n",
    "print(f'Processed set S3 location: {PROCESSED_SET_S3_BASE_URI}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33c0253-12fb-4370-a4f2-c6ad57d044c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/preprocessor.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pickle import dump\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "DEFAULT_BASE_DIR = Path('/opt')/'ml'/'processing'\n",
    "DATA_DIR='./dataset'\n",
    "\n",
    "def _preprocess_pipeline(df_data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:    \n",
    "    num_classes = 10\n",
    "\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            ('encoder', OneHotEncoder())            \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('labels', categorical_transformer, ['label'])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", preprocessor)\n",
    "        ]\n",
    "    )\n",
    "    data: np.ndarray = pipeline.fit_transform(df_data)\n",
    "    # OneHotEncoded\n",
    "    y_data: np.ndarray = data[:, :num_classes]\n",
    "    # Drop OneHotEncoded target variable\n",
    "    data = np.delete(data,np.arange(num_classes), axis=1)\n",
    "\n",
    "    X_train, X_test_validation, y_data, y_test_validation = train_test_split(data, y_data, test_size=0.2, random_state=7)\n",
    "    X_test, X_validation, y_test, y_validation = train_test_split(X_test_validation, y_test_validation, test_size=0.5, random_state=7)\n",
    "\n",
    "    return X_train, X_test, X_validation, y_data, y_test, y_validation\n",
    "\n",
    "\n",
    "def _save_pipeline(base_dir: str, pipeline: Pipeline):  \n",
    "    \n",
    "    pipeline_path = Path(base_dir)\n",
    "    pipeline_path.mkdir(parents=True, exist_ok=True)\n",
    "    dump(pipeline, open(pipeline_path / 'pipeline.pkl', 'wb'))\n",
    "\n",
    "def preprocess(base_dir, data_dir):\n",
    "    \n",
    "    if base_dir is None:\n",
    "        base_dir = DEFAULT_BASE_DIR\n",
    "        \n",
    "    base_dir = Path(base_dir)\n",
    "    (base_dir / 'train').mkdir(parents=True, exist_ok=True)\n",
    "    (base_dir / 'validation').mkdir(parents=True, exist_ok=True)\n",
    "    (base_dir / 'test').mkdir(parents=True, exist_ok=True)\n",
    "    (base_dir / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    df_data: pd.DataFrame =  pd.read_csv(Path(data_dir) / 'mnist_train.csv')\n",
    "\n",
    "    # df_test: pd.DataFrame =  pd.read_csv(Path(data_dir) / 'mnist_test.csv')\n",
    "\n",
    "    df_data: pd.Dataframe = df_data.sample(frac=0.5, random_state=1)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(df_data['label'])\n",
    "\n",
    "    X_train, X_test, X_validation, y_train, y_test, y_validation  = _preprocess_pipeline(df_data)    \n",
    "\n",
    "    np.savetxt(base_dir / 'train' / 'mnist_train.csv', np.concatenate([X_train, y_train], axis=1), delimiter=',')\n",
    "    np.savetxt(base_dir / 'test' / 'mnist_test.csv', np.concatenate([X_test, y_test], axis=1), delimiter=',')\n",
    "    np.savetxt(base_dir / 'validation' / 'mnist_validation.csv', np.concatenate([X_validation, y_validation], axis=1), delimiter=',')\n",
    "    np.savetxt(base_dir / 'labels' / 'labels.csv', labels, delimiter=',')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--base_dir', type=str, dest='base_dir', default=DEFAULT_BASE_DIR)\n",
    "    parser.add_argument('--data_dir', type=str, dest='data_dir', default=DATA_DIR)\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    preprocess(\n",
    "        base_dir=args.base_dir,\n",
    "        data_dir=arg.data_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06b8d4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from train import train\n",
    "from joblib import Memory\n",
    "from typing import Tuple\n",
    "from preprocessor import preprocess\n",
    "\n",
    "# memory = Memory(location='./cache', verbose=0)\n",
    "\n",
    "# @memory.cache\n",
    "def load_csv(test_path, train_path, validation_path,  sample=None) -> Tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n",
    "    num_classes = 10\n",
    "    \n",
    "    df = pd.read_csv(Path(train_path) / 'mnist_train.csv')\n",
    "    df_X_train = df.sample(frac=0.5, random_state=1)\n",
    "    df_X_test = df.sample(frac=0.5, random_state=1)\n",
    "    # X_train = np.genfromtxt(directory / 'train' / 'mnist_train.csv', delimiter=',')\n",
    "    # X_test = np.genfromtxt(directory / 'test' / 'mnist_test.csv', delimiter=',')\n",
    "    \n",
    "\n",
    "    y_train = df_X_train.values[:, -num_classes:]\n",
    "    y_test = df_X_test.values[:, -num_classes:]\n",
    "    \n",
    "    \n",
    "    return df_X_train.values, y_train, df_X_test.values, y_test\n",
    "\n",
    "# preprocess(\n",
    "#     base_dir='./preprocessed_dataset',\n",
    "#     data_dir='./dataset'\n",
    "# )\n",
    "\n",
    "# X_train, y_train, X_test, y_test = load_csv(0.1)\n",
    "\n",
    "# train(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7ce0bd7-481e-43b2-9155-5330e99aa4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/train.py\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import numpy as np\n",
    "from joblib import Memory\n",
    "from typing import Tuple\n",
    "from preprocessor import preprocess\n",
    "\n",
    "model_path = Path('model') / '001'\n",
    "image_size = 28 * 28\n",
    "\n",
    "def load_csv(test_path, train_path, validation_path,  sample=None) -> Tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n",
    "    num_classes = 10\n",
    "    \n",
    "    df = pd.read_csv(Path(train_path) / 'mnist_train.csv')\n",
    "    df_X_train = df.sample(frac=0.5, random_state=1)\n",
    "    df_X_test = df.sample(frac=0.5, random_state=1)\n",
    "    # X_train = np.genfromtxt(directory / 'train' / 'mnist_train.csv', delimiter=',')\n",
    "    # X_test = np.genfromtxt(directory / 'test' / 'mnist_test.csv', delimiter=',')\n",
    "    \n",
    "\n",
    "    y_train = df_X_train.values[:, -num_classes:]\n",
    "    y_test = df_X_test.values[:, -num_classes:]\n",
    "    \n",
    "    \n",
    "    return df_X_train.values, y_train, df_X_test.values, y_test\n",
    "\n",
    "def create(no_features):  \n",
    "    model = Sequential([\n",
    "        Dense(32, activation='sigmoid'),\n",
    "        Dense(10, activation='softmax'),\n",
    "    ])\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.build(input_shape=(None,no_features)) # Comeback to this, find out what 'None' is.  \n",
    "    return model\n",
    "\n",
    "def train(base_directory,\n",
    "          train_path, \n",
    "          validation_path,\n",
    "          epochs=10):\n",
    "    \n",
    "        # directory = Path('./preprocessed_dataset/')\n",
    "    X_train, y_train, X_test, y_test = load_csv(base_directory, \n",
    "                                                train_path, \n",
    "                                                validation_path,\n",
    "                                                0.1)\n",
    "    \n",
    "    model = create(X_train.shape[1])\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, batch_size=18, epochs=5, validation_split=.1, verbose=True)\n",
    "    model.save(model_path)\n",
    "\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=True)\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.plot(accuracy)\n",
    "\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training', 'validation'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    print(f'Loss: {loss:.3}, Accuracy: {accuracy:.3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b10fd848-a3b3-442d-bb8e-3c6bacdbe198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/evaluation.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "MODEL_PATH = \"/opt/ml/processing/model/\"\n",
    "TEST_PATH = \"/opt/ml/processing/test/\"\n",
    "OUTPUT_PATH = \"/opt/ml/processing/evaluation/\"\n",
    "\n",
    "\n",
    "def evaluate(model_path, test_path, output_path):\n",
    "    # The first step is to extract the model package so we can load \n",
    "    # it in memory.\n",
    "    with tarfile.open(Path(model_path) / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=Path(model_path))\n",
    "        \n",
    "    model = keras.models.load_model(Path(model_path) / \"001\")\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_csv(0.1, test_path)\n",
    "    # y_test = X_test[X_test.columns[-1]]\n",
    "    # X_test.drop(X_test.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "    predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Test accuracy: {accuracy}\")\n",
    "\n",
    "    # Let's create an evaluation report using the model accuracy.\n",
    "    evaluation_report = {\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": {\n",
    "                \"value\": accuracy\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_path) / \"evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(evaluation_report))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(\n",
    "        model_path='./model', \n",
    "        test_path=TEST_PATH,\n",
    "        output_path=OUTPUT_PATH\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e9036f5-b63e-4c96-879d-c55d493a5026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-d07e89ee73bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     train(\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mbase_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml.school/mnist/code/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(base_directory, train_path, validation_path, epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# directory = Path('./preprocessed_dataset/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     X_train, y_train, X_test, y_test = load_csv(base_directory, \n\u001b[0m\u001b[1;32m     48\u001b[0m                                                 \u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                                                 \u001b[0mvalidation_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml.school/mnist/code/train.py\u001b[0m in \u001b[0;36mload_csv\u001b[0;34m(test_path, train_path, validation_path, sample)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'mnist_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mdf_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdf_X_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from preprocessor import preprocess\n",
    "from train import train\n",
    "from evaluation import evaluate\n",
    "import tempfile, tarfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    preprocess(\n",
    "        base_dir=directory,\n",
    "        data_dir='./dataset'\n",
    "    )\n",
    "    \n",
    "    train(\n",
    "        base_directory=directory, \n",
    "        train_path=Path(directory) / \"train\", \n",
    "        validation_path=Path(directory) / \"validation\",\n",
    "        epochs=10\n",
    "    )\n",
    "    \n",
    "    # After training a model, we need to prepare a package just like\n",
    "    # SageMaker would. This package is what the evaluation script is\n",
    "    # expecting as an input.\n",
    "    with tarfile.open(Path(directory) / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(Path(directory) / \"model\" / \"001\", arcname=\"001\")\n",
    "    \n",
    "        evaluate(\n",
    "            model_path=Path(directory) / \"model\" / \"001\", \n",
    "            test_path=TEST_PATH,\n",
    "            output_path=OUTPUT_PATH\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909be96-b0d4-4f90-84ff-23214bfa2cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tempfile  \n",
    "from preprocessor import preprocess\n",
    "\n",
    "\n",
    "directory = Path('./preprocessed_dataset')\n",
    "directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "preprocess(\n",
    "    base_dir=directory,\n",
    "    data_dir=Path(DATASET_FOLDER),\n",
    ")\n",
    "print(f'Folders: {os.listdir(directory)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba99ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "from sagemaker.tuner import HyperParameter \n",
    "\n",
    "train_input= ParameterString(\n",
    "    name='train_data_location',\n",
    "    default_value=TRAIN_SET_S3_URI\n",
    ")\n",
    "\n",
    "test_input= ParameterString(\n",
    "    name='test_data_location',\n",
    "    default_value=TEST_SET_S3_URI\n",
    ")\n",
    "\n",
    "processed_data_output_location= ParameterString(\n",
    "    name='processed_data_output_location',\n",
    "    default_value=PROCESSED_SET_S3_URI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0821f-63a5-4e6f-a0b1-6b921e8d61e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "cache_config = CacheConfig(\n",
    "    enable_caching=True,\n",
    "    expire_after='15d',\n",
    ")\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m3.medium\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "preprocessing_step = ProcessingStep(\n",
    "    name='mnist_preprocessing',\n",
    "    processor = sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=train_input, destination='/opt/ml/processing/train'),\n",
    "        ProcessingInput(source=test_input, destination='/opt/ml/processing/test'),\n",
    "    ],\n",
    "    outputs = [\n",
    "        ProcessingOutput(output_name='train', source='/opt/ml/processing/train', destination=processed_data_output_location),\n",
    "        ProcessingOutput(output_name='validation', source='/opt/ml/processing/validation', destination=processed_data_output_location),\n",
    "        ProcessingOutput(output_name='test', source='/opt/ml/processing/test', destination=processed_data_output_location),\n",
    "    ],\n",
    "    code='code/preprocessor.py',\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca87f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensorflow_processor = TensorFlow(\n",
    "    entry_point=f'{CODE_FOLDER}/train.py'\n",
    "    framework_version='2.6',\n",
    "    role=role,\n",
    "    instance_type='m1.m3.medium',\n",
    "    instance_count=1,\n",
    "    base_job_name='mnist_train'\n",
    "    py_version='py38',\n",
    ")\n",
    "\n",
    "step_args = tensorflow.fit(\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        'train': TrainingInput(\n",
    "            s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'train'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv'\n",
    "        ),\n",
    "        'validation': TrainingInput(\n",
    "            s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'validation'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv'\n",
    "        ),\n",
    "        'test': TrainingInput(\n",
    "            s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'test'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv'\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name='mnist_train',\n",
    "    step_args=step_args,\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline(\n",
    "    name=\"mnist_pipeline\",\n",
    "    parameters=[\n",
    "        train_input_location,\n",
    "        test_input_location,\n",
    "        processed_data_output_location,\n",
    "    ],\n",
    "    steps=[preprocessing_step, training_step, validation_step, registration_step],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0998c853-71e4-42e8-aa0d-77600d1e04c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-north-1:243637512696:image/tensorflow-2.6-cpu-py38-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
