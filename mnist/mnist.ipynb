{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "505a53a1-babe-4238-ad19-e401a9f0a4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.8/site-packages (21.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting scikit-learn==1.3.0\n",
      "  Using cached scikit_learn-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn==1.3.0) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn==1.3.0) (1.7.0)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/site-packages (from scikit-learn==1.3.0) (1.19.5)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pandas==1.3.3\n",
      "  Using cached pandas-1.3.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/site-packages (from pandas==1.3.3) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/site-packages (from pandas==1.3.3) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/site-packages (from pandas==1.3.3) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.3.3) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.2.5\n",
      "    Uninstalling pandas-1.2.5:\n",
      "      Successfully uninstalled pandas-1.2.5\n",
      "Successfully installed pandas-1.3.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/site-packages (1.3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting matplotlib==3.6.0\n",
      "  Using cached matplotlib-3.6.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (8.3.2)\n",
      "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (1.19.5)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (4.28.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib==3.6.0) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib==3.6.0) (1.15.0)\n",
      "Installing collected packages: contourpy, matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.5.0\n",
      "    Uninstalling matplotlib-3.5.0:\n",
      "      Successfully uninstalled matplotlib-3.5.0\n",
      "Successfully installed contourpy-1.1.0 matplotlib-3.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -q --upgrade awscli boto3\n",
    "# !pip install -q --upgrade PyYAML==6.0\n",
    "!pip install -q --upgrade sagemaker==2.165.0\n",
    "!pip install pip\n",
    "!pip install scikit-learn==1.3.0\n",
    "!pip install pandas==1.3.3\n",
    "!pip install joblib\n",
    "!pip install matplotlib==3.6.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8736d294-1434-4739-82a3-d0e7414a41bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b96a6d2-3cd1-49ca-8219-8929c93b741d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::253909639528:role/service-role/AmazonSageMaker-ExecutionRole-20230826T112945'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlowProcessor\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.parameters import ParameterString, ParameterFloat\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import CacheConfig, ProcessingStep, TrainingStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo, ConditionLessThan\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "\n",
    "\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ee4d0e-d3a6-4ac3-bd60-e04dd7028ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'vmate-mnist-1'\n",
    "\n",
    "!aws s3api create-bucket --bucket $BUCKET --create-bucket-configuration LocationConstraint=\"eu-north-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df65826-f4e1-4683-8bfe-b7889bf8eec9",
   "metadata": {},
   "source": [
    "Let's load the first 10 rows of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a47f00d-c97c-4dde-b588-21c1f3782c12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "5      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "6      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "7      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "8      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "9      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "5      0      0      0      0      0      0      0      0  \n",
       "6      0      0      0      0      0      0      0      0  \n",
       "7      0      0      0      0      0      0      0      0  \n",
       "8      0      0      0      0      0      0      0      0  \n",
       "9      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_FOLDER / 'mnist_train.csv', nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b66235d0-2ff6-4220-8608-31f0e0ac959f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set S3 location: s3://vmate-mnist-1/mnist/mnist_train.csv\n",
      "Test set S3 location: s3://vmate-mnist-1/mnist/mnist_test.csv\n",
      "Processed set S3 location: s3://vmate-mnist-1/mnist/preprocessed_data\n"
     ]
    }
   ],
   "source": [
    "S3_LOCATION = f's3://{BUCKET}/mnist'\n",
    "\n",
    "TRAIN_SET_S3_URI = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=str(DATASET_FOLDER / 'mnist_train.csv'), \n",
    "    desired_s3_uri=S3_LOCATION,\n",
    ")\n",
    "\n",
    "TEST_SET_S3_URI = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=str(DATASET_FOLDER / 'mnist_test.csv'), \n",
    "    desired_s3_uri=S3_LOCATION,\n",
    ")\n",
    "\n",
    "PROCESSED_SET_S3_BASE_URI = f's3://{BUCKET}/mnist/preprocessed_data'\n",
    "\n",
    "\n",
    "print(f'Train set S3 location: {TRAIN_SET_S3_URI}')\n",
    "print(f'Test set S3 location: {TEST_SET_S3_URI}')\n",
    "print(f'Processed set S3 location: {PROCESSED_SET_S3_BASE_URI}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33c0253-12fb-4370-a4f2-c6ad57d044c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/preprocessor.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pickle import dump\n",
    "from typing import Tuple\n",
    "import argparse\n",
    "\n",
    "DEFAULT_BASE_DIR = Path('/opt')/'ml'/'processing'\n",
    "\n",
    "def _preprocess_pipeline(df_data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:    \n",
    "    num_classes = 10\n",
    "\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            ('encoder', OneHotEncoder())            \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('labels', categorical_transformer, ['label'])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", preprocessor)\n",
    "        ]\n",
    "    )\n",
    "    data: np.ndarray = pipeline.fit_transform(df_data)\n",
    "    # OneHotEncoded\n",
    "    y_data: np.ndarray = data[:, :num_classes]\n",
    "    # Drop OneHotEncoded target variable\n",
    "    data = np.delete(data,np.arange(num_classes), axis=1)\n",
    "\n",
    "    X_train, X_test_validation, y_data, y_test_validation = train_test_split(data, y_data, test_size=0.2, random_state=7)\n",
    "    X_test, X_validation, y_test, y_validation = train_test_split(X_test_validation, y_test_validation, test_size=0.5, random_state=7)\n",
    "\n",
    "    return X_train, X_test, X_validation, y_data, y_test, y_validation\n",
    "\n",
    "\n",
    "def _save_pipeline(base_dir: str, pipeline: Pipeline):  \n",
    "    \n",
    "    pipeline_path = Path(base_dir)\n",
    "    pipeline_path.mkdir(parents=True, exist_ok=True)\n",
    "    dump(pipeline, open(pipeline_path / 'pipeline.pkl', 'wb'))\n",
    "\n",
    "def preprocess(base_dir = DEFAULT_BASE_DIR, data_dir=DEFAULT_BASE_DIR):\n",
    "            \n",
    "    base_dir = Path(base_dir)\n",
    "    data_dir = Path(data_dir)\n",
    "        \n",
    "    (base_dir / 'train').mkdir(parents=True, exist_ok=True)\n",
    "    (base_dir / 'validation').mkdir(parents=True, exist_ok=True)\n",
    "    (base_dir / 'test').mkdir(parents=True, exist_ok=True)\n",
    "    (base_dir / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    df_data: pd.DataFrame =  pd.read_csv(Path(data_dir) / 'mnist_train.csv')\n",
    "\n",
    "    df_data: pd.Dataframe = df_data.sample(frac=0.5, random_state=1)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(df_data['label'])\n",
    "\n",
    "    X_train, X_test, X_validation, y_train, y_test, y_validation  = _preprocess_pipeline(df_data)    \n",
    "\n",
    "    np.savetxt(base_dir / 'train' / 'mnist_train.csv', np.concatenate([X_train, y_train], axis=1), delimiter=',')\n",
    "    np.savetxt(base_dir / 'test' / 'mnist_test.csv', np.concatenate([X_test, y_test], axis=1), delimiter=',')\n",
    "    np.savetxt(base_dir / 'validation' / 'mnist_validation.csv', np.concatenate([X_validation, y_validation], axis=1), delimiter=',')\n",
    "    np.savetxt(base_dir / 'labels' / 'labels.csv', labels, delimiter=',')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--base_dir', type=str, dest='base_dir', default=DEFAULT_BASE_DIR)\n",
    "    parser.add_argument('--data_dir', type=str, dest='data_dir', default=\"/opt/ml/processing/input\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    preprocess(\n",
    "        base_dir=args.base_dir,\n",
    "        data_dir=args.data_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7ce0bd7-481e-43b2-9155-5330e99aa4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/train.py\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Memory\n",
    "from typing import Tuple\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "image_size = 28 * 28\n",
    "\n",
    "def load_csv(file_path,  sample=None) -> Tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n",
    "    num_classes = 10\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    df_X_train = df.sample(frac=sample, random_state=1)\n",
    "    df_X_test = df.sample(frac=sample, random_state=1)\n",
    "\n",
    "    y_train = df_X_train.values[:, -num_classes:]\n",
    "    y_test = df_X_test.values[:, -num_classes:]\n",
    "    \n",
    "    \n",
    "    return df_X_train.values, y_train, df_X_test.values, y_test\n",
    "\n",
    "def create(no_features):  \n",
    "    model = Sequential([\n",
    "        Dense(32, activation='sigmoid'),\n",
    "        Dense(10, activation='softmax'),\n",
    "    ])\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.build(input_shape=(None,no_features)) # Comeback to this, find out what 'None' is.  \n",
    "    return model\n",
    "\n",
    "def train(train_dir,\n",
    "          model_dir,\n",
    "          epochs=10,\n",
    "          batch_size=16):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_csv(Path(train_dir) / \"mnist_train.csv\", \n",
    "                                                0.5)\n",
    "    \n",
    "    model = create(X_train.shape[1])\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=True)\n",
    "    model.save(Path(model_dir) / \"001\")\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=True)\n",
    "\n",
    "    print(f'MODEL_DIRECTORY: {model_dir}')\n",
    "    print(f'Loss: {loss:.3}, Accuracy: {accuracy:.3}')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # https://github.com/aws/sagemaker-training-toolkit/blob/master/src/sagemaker_training/params.py\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train_dir\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\", None))\n",
    "    parser.add_argument(\"--model_dir\", type=str, default='/opt/ml/model')\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    train(\n",
    "        train_dir=args.train_dir,\n",
    "        model_dir=\"/opt/ml/model\",\n",
    "    )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10fd848-a3b3-442d-bb8e-3c6bacdbe198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/evaluation.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from typing import Tuple\n",
    "# from train import load_csv\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "MODEL_PATH = \"/opt/ml/processing/model\"\n",
    "TEST_PATH = \"/opt/ml/processing/test\"\n",
    "OUTPUT_PATH = \"/opt/ml/processing/evaluation\"\n",
    "\n",
    "def load_csv(file_path,  sample=None) -> Tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n",
    "    num_classes = 10\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    df_X_train = df.sample(frac=sample, random_state=1)\n",
    "    df_X_test = df.sample(frac=sample, random_state=1)\n",
    "\n",
    "    y_train = df_X_train.values[:, -num_classes:]\n",
    "    y_test = df_X_test.values[:, -num_classes:]\n",
    "    \n",
    "    return df_X_train.values, y_train, df_X_test.values, y_test\n",
    "\n",
    "def evaluate(model_path, test_path, output_path):\n",
    "    # The first step is to extract the model package so we can load \n",
    "    # it in memory.\n",
    "    with tarfile.open(Path(model_path) / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=Path(model_path))\n",
    "        \n",
    "    model = keras.models.load_model(Path(model_path) / \"001\")\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_csv(Path(test_path) / \"mnist_test.csv\", 0.5)\n",
    "\n",
    "    \n",
    "    predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "    encoder = OneHotEncoder()\n",
    "    predictions = encoder.fit_transform(predictions.reshape(-1,1)) # Reshape to a 2-D array\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Test accuracy: {accuracy}\")\n",
    "\n",
    "    # Let's create an evaluation report using the model accuracy.\n",
    "    evaluation_report = {\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": {\n",
    "                \"value\": accuracy\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_path) / \"evaluation.json\", \"w\") as f:\n",
    "        f.write(json.dumps(evaluation_report))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate(\n",
    "        model_path=MODEL_PATH, \n",
    "        test_path=TEST_PATH,\n",
    "        output_path=OUTPUT_PATH\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e9036f5-b63e-4c96-879d-c55d493a5026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['processing']\n",
      "processing\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                25440     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,770\n",
      "Trainable params: 25,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Extension horovod.torch has not been built: /usr/local/lib/python3.8/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-38-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2023-09-04 09:27:32.310 tensorflow-2-6-cpu-py-ml-t3-medium-97b05bbe92bff9d43abb12500182:52 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2023-09-04 09:27:32.632 tensorflow-2-6-cpu-py-ml-t3-medium-97b05bbe92bff9d43abb12500182:52 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "675/675 [==============================] - 4s 4ms/step - loss: 1.6859 - accuracy: 0.5338 - val_loss: 1.2811 - val_accuracy: 0.6933\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpid5r4y22/model/001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpid5r4y22/model/001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 2s 4ms/step - loss: 1.2792 - accuracy: 0.6998\n",
      "MODEL_DIRECTORY: /tmp/tmpid5r4y22/model\n",
      "Loss: 1.28, Accuracy: 0.7\n",
      "Test accuracy: 0.6913333333333334\n"
     ]
    }
   ],
   "source": [
    "from preprocessor import preprocess\n",
    "from train import train\n",
    "from evaluation import evaluate\n",
    "import tempfile, tarfile\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "\n",
    "    preprocess(\n",
    "        base_dir=f\"{directory}/processing\",\n",
    "        data_dir='./dataset'\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        train_dir=f\"{directory}/processing/train\",\n",
    "        model_dir=Path(directory) / \"model\",\n",
    "        epochs=1\n",
    "    )\n",
    "    \n",
    "    with tarfile.open(Path(directory) / \"model\" / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(Path(directory) / \"model\" / \"001\", arcname=\"001\")\n",
    "\n",
    "    evaluate(\n",
    "        model_path=Path(directory) / \"model\", \n",
    "        test_path=Path(directory) / \"processing\" / \"test\",\n",
    "        output_path=Path(directory) / \"evaluation\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ba99ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "\n",
    "train_input= ParameterString(\n",
    "    name='train_data_location',\n",
    "    default_value=TRAIN_SET_S3_URI\n",
    ")\n",
    "\n",
    "test_input= ParameterString(\n",
    "    name='test_data_location',\n",
    "    default_value=TEST_SET_S3_URI\n",
    ")\n",
    "\n",
    "processed_data_output_location= ParameterString(\n",
    "    name='processed_data_output_location',\n",
    "    default_value=PROCESSED_SET_S3_BASE_URI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ced0821f-63a5-4e6f-a0b1-6b921e8d61e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "cache_config = CacheConfig(\n",
    "    enable_caching=True,\n",
    "    expire_after='15d',\n",
    ")\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "preprocessing_step = ProcessingStep(\n",
    "    name='preprocessing',\n",
    "    processor = sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=train_input, destination='/opt/ml/processing/input'),\n",
    "    ],\n",
    "    outputs = [\n",
    "        ProcessingOutput(output_name='train', source='/opt/ml/processing/train', destination=processed_data_output_location),\n",
    "        ProcessingOutput(output_name='validation', source='/opt/ml/processing/validation', destination=processed_data_output_location),\n",
    "        ProcessingOutput(output_name='test', source='/opt/ml/processing/test', destination=processed_data_output_location),\n",
    "    ],\n",
    "    code='code/preprocessor.py',\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eca87f34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "/usr/local/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py:286: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n",
      "INFO:sagemaker.tensorflow.model:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "tensorflow_processor = TensorFlowProcessor(\n",
    "    framework_version='2.6',\n",
    "    role=role,\n",
    "    instance_type='ml.t3.medium',\n",
    "    instance_count=1,\n",
    "    py_version='py38',\n",
    "    sagemaker_session=PipelineSession()    \n",
    ")\n",
    "\n",
    "# This is a workaround to a problem with the SageMaker SDK: \n",
    "# By default, the TensorFlowProcessor runs the script using\n",
    "# /bin/bash as its entrypoint. We want to ensure we run it \n",
    "# using python3.\n",
    "tensorflow_processor.framework_entrypoint_command = [\"python3\"]\n",
    "\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point=f\"{CODE_FOLDER}/train.py\",    \n",
    "    framework_version=\"2.6\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    py_version=\"py38\",\n",
    "    instance_count=1,\n",
    "    script_mode=True,\n",
    "    \n",
    "    # The default profiler rule includes a timestamp which will change each time\n",
    "    # the pipeline is upserted, causing cache misses. Since we don't need\n",
    "    # profiling, we can disable it to take advantage of caching.\n",
    "    disable_profiler=True,\n",
    "\n",
    "    role=role,\n",
    "    sagemaker_session=PipelineSession(),\n",
    ")\n",
    "\n",
    "step_args = estimator.fit(\n",
    "    inputs={\n",
    "        'train': TrainingInput(\n",
    "            s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'train'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv'\n",
    "        ),\n",
    "        'validation': TrainingInput(\n",
    "            s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'validation'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv'\n",
    "        ),\n",
    "        'test': TrainingInput(\n",
    "            s3_data=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'test'\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type='text/csv'\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name='train',\n",
    "    step_args=step_args,\n",
    "    cache_config=cache_config,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"evaluation-report\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "evaluation_step = ProcessingStep(\n",
    "    processor=tensorflow_processor,\n",
    "    name=\"evaluation\",\n",
    "    inputs=[\n",
    "        ProcessingInput(source=preprocessing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"test\"\n",
    "        ].S3Output.S3Uri,\n",
    "        destination=\"/opt/ml/processing/test\"\n",
    "    ),\n",
    "    ProcessingInput(\n",
    "        source=(\n",
    "            training_step.properties.ModelArtifacts.S3ModelArtifacts\n",
    "        ),\n",
    "        destination=\"/opt/ml/processing/model\",\n",
    "    )],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\", destination=f\"{S3_LOCATION}/evaluation\"),\n",
    "    ],\n",
    "    code=f\"{CODE_FOLDER}/evaluation.py\",\n",
    "    cache_config=cache_config,\n",
    "    property_files=[evaluation_report],\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(on=\"/\", values=[\n",
    "            evaluation_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri'],\"evaluation.json\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "model_package_group_name = \"mnist\"\n",
    "model = TensorFlowModel(\n",
    "    model_data=(\n",
    "        training_step.properties.ModelArtifacts.S3ModelArtifacts\n",
    "    ),\n",
    "    framework_version=\"2.6\",\n",
    "    sagemaker_session=PipelineSession(),\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "def create_model_registry_args(model, model_package_group_name, model_metrics, approval_status=\"PendingManualApproval\"):\n",
    "    return model.register(\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        model_metrics=model_metrics,\n",
    "        approval_status=approval_status,      \n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"text/csv\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        transform_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"TENSORFLOW\",\n",
    "        framework_version=\"2.6\",\n",
    "    )\n",
    "\n",
    "register_args_approval = create_model_registry_args(model, \n",
    "                                                    model_package_group_name, \n",
    "                                                    model_metrics, \n",
    "                                                    \"Approved\")\n",
    "\n",
    "register_args_pending = create_model_registry_args(model,\n",
    "                                                model_package_group_name, \n",
    "                                                model_metrics)\n",
    "\n",
    "register_model_step_approved = ModelStep(\n",
    "    name=\"register-model-approved_step\",\n",
    "    step_args=register_args_approval,\n",
    ")\n",
    "\n",
    "register_model_step_pending = ModelStep(\n",
    "    name=\"register-model-pending\",\n",
    "    step_args=register_args_pending,\n",
    ")\n",
    "\n",
    "accuracy_threshold = ParameterFloat(\n",
    "    name=\"accuracy_threshold\", \n",
    "    default_value=0.70\n",
    ")\n",
    "\n",
    "min_accuracy_threshold = ParameterFloat(\n",
    "    name=\"accuracy_threshold_min\", \n",
    "    default_value=0.50\n",
    ")\n",
    "\n",
    "condition_gte = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.accuracy.value\"\n",
    "    ),\n",
    "    right=accuracy_threshold\n",
    ")\n",
    "\n",
    "condition_lt = ConditionLessThan(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.accuracy.value\"\n",
    "    ),\n",
    "    right=min_accuracy_threshold\n",
    ")\n",
    "\n",
    "fail_step_min = FailStep(\n",
    "    name=\"fail-min\",\n",
    "    error_message=Join(\n",
    "        on=\" \", \n",
    "        values=[\n",
    "            \"Execution failed because the model's accuracy was lower than\", \n",
    "            min_accuracy_threshold\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "model_registry_approved = ConditionStep(\n",
    "    name=\"register-model-approved\",\n",
    "    conditions=[condition_gte],\n",
    "    if_steps=[register_model_step_approved],\n",
    "    else_steps=[fail_step_min]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6b0b948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:eu-north-1:253909639528:pipeline/mnist/execution/d4ivvlrxjhhu', sagemaker_session=<sagemaker.session.Session object at 0x7f9c30e05730>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline(\n",
    "    name=\"mnist\",\n",
    "    parameters=[\n",
    "        train_input,\n",
    "        test_input,\n",
    "        processed_data_output_location,\n",
    "        accuracy_threshold,\n",
    "        min_accuracy_threshold,\n",
    "    ],\n",
    "    steps=[preprocessing_step,\n",
    "           training_step,\n",
    "           evaluation_step,\n",
    "           model_registry_approved,\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.upsert(role_arn=role)\n",
    "pipeline.start()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "kernelspec": {
   "display_name": "mnist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
