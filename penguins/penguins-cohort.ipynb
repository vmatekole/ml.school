{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c712cfc-5ac2-481f-8019-815e97bfeca2",
   "metadata": {},
   "source": [
    "**Note:** Make sure you go through the [Setup Notebook](penguins-setup.ipynb) notebook once at the start of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de2fcd6-69c7-461d-bd80-771db1ba5fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mName: sagemaker\n",
      "Version: 2.173.0\n",
      "Summary: Open source library for training and deploying models on Amazon SageMaker.\n",
      "Home-page: https://github.com/aws/sagemaker-python-sdk/\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: /opt/conda/lib/python3.8/site-packages\n",
      "Requires: attrs, boto3, cloudpickle, google-pasta, importlib-metadata, jsonschema, numpy, packaging, pandas, pathos, platformdirs, protobuf, PyYAML, schema, smdebug-rulesconfig, tblib\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# !pip install -q --upgrade pip\n",
    "# !pip install -q --upgrade awscli boto3\n",
    "!pip install -q --upgrade scikit-learn==0.23.2\n",
    "# !pip install -q --upgrade PyYAML==6.0\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q --upgrade awscli boto3\n",
    "!pip install -q --upgrade sagemaker==2.173.0\n",
    "!pip show sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a5f8ec-113a-4f91-8f66-eab31d934bab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "CODE_FOLDER = Path(\"code\")\n",
    "CODE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sys.path.append(f\"./{CODE_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915b1d0b-d9da-4529-aca5-fd1c08a36f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import time\n",
    "import tarfile\n",
    "\n",
    "from constants import *\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.parameters import ParameterString, ParameterFloat\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.parameter import IntegerParameter, ContinuousParameter\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker.pytorch import PyTorchProcessor\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics \n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo, ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "MODEL_PACKAGE_GROUP = \"penguins\"\n",
    "ENDPOINT=\"penguins-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb6ba7c0-1bd6-4fe5-8b7f-f6cbdfd3846c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/preprocessor.py\n",
    "\n",
    "## Preprocessing script\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from pickle import dump\n",
    "\n",
    "\n",
    "# This is the location where the SageMaker Processing job\n",
    "# will save the input dataset.\n",
    "BASE_DIRECTORY = \"/opt/ml/processing\"\n",
    "DATA_FILEPATH = Path(BASE_DIRECTORY) / \"input\" / \"data.csv\"\n",
    "\n",
    "\n",
    "def _save_splits(base_directory, train, validation, test):\n",
    "    \"\"\"\n",
    "    One of the goals of this script is to output the three\n",
    "    dataset splits. This function will save each of these\n",
    "    splits to disk.\n",
    "    \"\"\"\n",
    "\n",
    "    train_path = Path(base_directory) / \"train\"\n",
    "    validation_path = Path(base_directory) / \"validation\"\n",
    "    test_path = Path(base_directory) / \"test\"\n",
    "\n",
    "    train_path.mkdir(parents=True, exist_ok=True)\n",
    "    validation_path.mkdir(parents=True, exist_ok=True)\n",
    "    test_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pd.DataFrame(train).to_csv(train_path / \"train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(\n",
    "        validation_path / \"validation.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(test).to_csv(test_path / \"test.csv\", header=False, index=False)\n",
    "\n",
    "\n",
    "def _save_pipeline(base_directory, pipeline):\n",
    "    \"\"\"\n",
    "    Saves the Scikit-Learn pipeline that we used to\n",
    "    preprocess the data.\n",
    "    \"\"\"\n",
    "    pipeline_path = Path(base_directory) / \"pipeline\"\n",
    "    pipeline_path.mkdir(parents=True, exist_ok=True)\n",
    "    dump(pipeline, open(pipeline_path / \"pipeline.pkl\", \"wb\"))\n",
    "\n",
    "\n",
    "def _save_classes(base_directory, classes):\n",
    "    \"\"\"\n",
    "    Saves the list of classes from the dataset.\n",
    "    \"\"\"\n",
    "    path = Path(base_directory) / \"classes\"\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    np.asarray(classes).tofile(path / \"classes.csv\", sep=\",\")\n",
    "\n",
    "\n",
    "def _save_baseline(base_directory, df_train, df_test):\n",
    "    \"\"\"\n",
    "    During the data and quality monitoring steps, we will need a baseline\n",
    "    to compute constraints and statistics. This function will save that\n",
    "    baseline to the disk.\n",
    "    \"\"\"\n",
    "\n",
    "    for split, data in [(\"train\", df_train), (\"test\", df_test)]:\n",
    "        baseline_path = Path(base_directory) / f\"{split}-baseline\"\n",
    "        baseline_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        df = data.copy().dropna()\n",
    "        df.to_json(\n",
    "            baseline_path / f\"{split}-baseline.json\", orient=\"records\", lines=True\n",
    "        )\n",
    "\n",
    "\n",
    "def preprocess(base_directory, data_filepath):\n",
    "    \"\"\"\n",
    "    Preprocesses the supplied raw dataset and splits it into a train,\n",
    "    validation, and a test set.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(data_filepath)\n",
    "\n",
    "    numeric_features = df.select_dtypes(include=['float64']).columns.tolist()\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"encoder\", OneHotEncoder()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"numeric\", numeric_transformer, numeric_features),\n",
    "            (\"categorical\", categorical_transformer, [\"island\"]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessing\", preprocessor)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    df.drop([\"sex\"], axis=1, inplace=True)\n",
    "    df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "    df_train, temp = train_test_split(df, test_size=0.3)\n",
    "    df_validation, df_test = train_test_split(temp, test_size=0.5)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(df_train.species)\n",
    "    y_validation = label_encoder.transform(df_validation.species)\n",
    "    y_test = label_encoder.transform(df_test.species)\n",
    "    \n",
    "    _save_baseline(base_directory, df_train, df_test)\n",
    "\n",
    "    df_train = df_train.drop([\"species\"], axis=1)\n",
    "    df_validation = df_validation.drop([\"species\"], axis=1)\n",
    "    df_test = df_test.drop([\"species\"], axis=1)\n",
    "\n",
    "    X_train = pipeline.fit_transform(df_train)\n",
    "    X_validation = pipeline.transform(df_validation)\n",
    "    X_test = pipeline.transform(df_test)\n",
    "\n",
    "    train = np.concatenate((X_train, np.expand_dims(y_train, axis=1)), axis=1)\n",
    "    validation = np.concatenate((X_validation, np.expand_dims(y_validation, axis=1)), axis=1)\n",
    "    test = np.concatenate((X_test, np.expand_dims(y_test, axis=1)), axis=1)\n",
    "\n",
    "    _save_splits(base_directory, train, validation, test)\n",
    "    _save_pipeline(base_directory, pipeline=pipeline)\n",
    "    _save_classes(base_directory, label_encoder.classes_)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess(BASE_DIRECTORY, DATA_FILEPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1f122a4-acff-4687-91b9-bfef13567d88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders: ['train-baseline', 'test-baseline', 'train', 'validation', 'test', 'pipeline', 'classes']\n"
     ]
    }
   ],
   "source": [
    "# Test preprocessing script\n",
    "\n",
    "from preprocessor import preprocess\n",
    "\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    preprocess(\n",
    "        base_directory=directory, \n",
    "        data_filepath=DATA_FILEPATH\n",
    "    )\n",
    "    \n",
    "    print(f\"Folders: {os.listdir(directory)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86de7edd-18b0-40d1-ac8e-0f3ef4469be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preprocess_data_step parameters\n",
    "dataset_location = ParameterString(\n",
    "    name=\"dataset_location\",\n",
    "    default_value=f\"{S3_LOCATION}/data.csv\",\n",
    ")\n",
    "\n",
    "preprocessor_destination = ParameterString(\n",
    "    name=\"preprocessor_destination\",\n",
    "    default_value=f\"{S3_LOCATION}/preprocessing\",\n",
    ")\n",
    "\n",
    "pipeline_definition_config = PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    "\n",
    "cache_config = CacheConfig(\n",
    "    enable_caching=True, \n",
    "    expire_after=\"15d\"\n",
    ")\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    base_job_name=\"penguins-preprocessing\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2187b65e-e504-40a5-ad05-82f54885805c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define preprocessing step\n",
    "preprocess_data_step = ProcessingStep(\n",
    "    name=\"preprocess-data\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=dataset_location, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "        ProcessingOutput(output_name=\"pipeline\", source=\"/opt/ml/processing/pipeline\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"classes\", source=\"/opt/ml/processing/classes\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"train-baseline\", source=\"/opt/ml/processing/train-baseline\"),\n",
    "        ProcessingOutput(output_name=\"test-baseline\", source=\"/opt/ml/processing/test-baseline\"),\n",
    "    ],\n",
    "    code=f\"{CODE_FOLDER}/preprocessor.py\",\n",
    "    cache_config=cache_config\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0977b424-38db-43b5-a187-ad8f35b2f4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/train.py\n",
    "#  Pytorch training script\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class PenguinModel(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(PenguinModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=input_shape, out_features=10)\n",
    "        self.fc2 = nn.Linear(in_features=10, out_features=8)\n",
    "        self.fc3 = nn.Linear(in_features=8, out_features=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)  # Apply softmax along dimension 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    # Prediction function\n",
    "    def predict(self, input_data):\n",
    "        input_data_torch = torch.tensor(input_data.values, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            self.eval()  # Set the model to evaluation mode\n",
    "            output = self(input_data_torch)\n",
    "        return output\n",
    "\n",
    "def train(base_directory, train_path, validation_path, epochs=50, batch_size=32, learning_rate=0.01):\n",
    "    X_train = pd.read_csv(Path(train_path) / \"train.csv\")\n",
    "    y_train = X_train[X_train.columns[-1]]\n",
    "    X_train.drop(X_train.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "    X_validation = pd.read_csv(Path(validation_path) / \"validation.csv\")\n",
    "    y_validation = X_validation[X_validation.columns[-1]] # Get the last column of the training dataset\n",
    "    X_validation.drop(X_validation.columns[-1], axis=1, inplace=True)\n",
    "   \n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_torch = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train_torch = torch.tensor(y_train.values, dtype=torch.long)\n",
    "    X_validation_torch = torch.tensor(X_validation.values, dtype=torch.float32)\n",
    "    y_validation_torch = torch.tensor(y_validation.values, dtype=torch.long)\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Initialize the model, loss, and optimizer\n",
    "    model = PenguinModel(X_train.shape[1])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "         # Calculate accuracy and average loss for the epoch\n",
    "        epoch_loss = total_loss / len(train_loader)\n",
    "        epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - loss: {epoch_loss:.4f}, val_accuracy: {epoch_accuracy:.4f}\")\n",
    "        \n",
    "    # Save model\n",
    "    model_path = Path(base_directory) / 'model' / '001'\n",
    "    model_path.mkdir(parents=True,exist_ok=True)\n",
    "    \n",
    "    torch.save(model.state_dict(), model_path / 'model.pth')\n",
    "    \n",
    "    print(f'Model saved: {model_path.resolve()}/model.pth')\n",
    "   \n",
    "if __name__ == \"__main__\":\n",
    "    # Any hyperparameters provided by the training job are passed to the entry point\n",
    "    # as script arguments. SageMaker will also provide a list of special parameters\n",
    "    # that you can capture here. Here is the full list: \n",
    "    # https://github.com/aws/sagemaker-training-toolkit/blob/master/src/sagemaker_training/params.py\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--base_directory\", type=str, default=\"/opt/ml/\")\n",
    "    # SageMaker will automatically create env variables(prefixed with SM_CHANNEL_) for the training inputs defined in the training step further below\n",
    "    parser.add_argument(\"--train_path\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\", None))  \n",
    "    parser.add_argument(\"--validation_path\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\", None))\n",
    "    parser.add_argument(\"--learning_rate\", type=float)\n",
    "    parser.add_argument(\"--epochs\", type=int)\n",
    "    parser.add_argument(\"--batch_size\", type=int)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    train(\n",
    "        base_directory=args.base_directory,\n",
    "        train_path=args.train_path,\n",
    "        validation_path=args.validation_path,\n",
    "        epochs=args.epochs,\n",
    "        learning_rate=args.learning_rate,\n",
    "        batch_size=args.batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7df253-77bf-44c2-9230-b41dbe28cc0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp {CODE_FOLDER}/train.py  {CODE_FOLDER}/endpoint/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14ea27ce-c453-4cb0-b309-dbecd732957e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-14 17:05:05.068 pytorch-1-10-cpu-py38-ml-t3-medium-8265974f1f54da4fb1fd6ac71882:1199 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-14 17:05:05.350 pytorch-1-10-cpu-py38-ml-t3-medium-8265974f1f54da4fb1fd6ac71882:1199 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Epoch [1/100] - loss: 1.0889, val_accuracy: 0.4059\n",
      "Epoch [2/100] - loss: 1.0886, val_accuracy: 0.4059\n",
      "Epoch [3/100] - loss: 1.0882, val_accuracy: 0.4059\n",
      "Epoch [4/100] - loss: 1.0878, val_accuracy: 0.4059\n",
      "Epoch [5/100] - loss: 1.0874, val_accuracy: 0.4059\n",
      "Epoch [6/100] - loss: 1.0870, val_accuracy: 0.4059\n",
      "Epoch [7/100] - loss: 1.0866, val_accuracy: 0.4059\n",
      "Epoch [8/100] - loss: 1.0863, val_accuracy: 0.4059\n",
      "Epoch [9/100] - loss: 1.0858, val_accuracy: 0.4059\n",
      "Epoch [10/100] - loss: 1.0854, val_accuracy: 0.4059\n",
      "Epoch [11/100] - loss: 1.0850, val_accuracy: 0.4059\n",
      "Epoch [12/100] - loss: 1.0845, val_accuracy: 0.4059\n",
      "Epoch [13/100] - loss: 1.0840, val_accuracy: 0.4059\n",
      "Epoch [14/100] - loss: 1.0836, val_accuracy: 0.4059\n",
      "Epoch [15/100] - loss: 1.0830, val_accuracy: 0.4059\n",
      "Epoch [16/100] - loss: 1.0825, val_accuracy: 0.4059\n",
      "Epoch [17/100] - loss: 1.0820, val_accuracy: 0.4059\n",
      "Epoch [18/100] - loss: 1.0815, val_accuracy: 0.4059\n",
      "Epoch [19/100] - loss: 1.0809, val_accuracy: 0.4059\n",
      "Epoch [20/100] - loss: 1.0803, val_accuracy: 0.4059\n",
      "Epoch [21/100] - loss: 1.0797, val_accuracy: 0.4059\n",
      "Epoch [22/100] - loss: 1.0791, val_accuracy: 0.4059\n",
      "Epoch [23/100] - loss: 1.0785, val_accuracy: 0.4059\n",
      "Epoch [24/100] - loss: 1.0779, val_accuracy: 0.4059\n",
      "Epoch [25/100] - loss: 1.0773, val_accuracy: 0.4059\n",
      "Epoch [26/100] - loss: 1.0766, val_accuracy: 0.4059\n",
      "Epoch [27/100] - loss: 1.0760, val_accuracy: 0.4059\n",
      "Epoch [28/100] - loss: 1.0753, val_accuracy: 0.4059\n",
      "Epoch [29/100] - loss: 1.0746, val_accuracy: 0.4059\n",
      "Epoch [30/100] - loss: 1.0739, val_accuracy: 0.4059\n",
      "Epoch [31/100] - loss: 1.0731, val_accuracy: 0.4059\n",
      "Epoch [32/100] - loss: 1.0724, val_accuracy: 0.4059\n",
      "Epoch [33/100] - loss: 1.0716, val_accuracy: 0.4059\n",
      "Epoch [34/100] - loss: 1.0708, val_accuracy: 0.4059\n",
      "Epoch [35/100] - loss: 1.0700, val_accuracy: 0.4059\n",
      "Epoch [36/100] - loss: 1.0692, val_accuracy: 0.4059\n",
      "Epoch [37/100] - loss: 1.0684, val_accuracy: 0.4059\n",
      "Epoch [38/100] - loss: 1.0675, val_accuracy: 0.4059\n",
      "Epoch [39/100] - loss: 1.0666, val_accuracy: 0.4059\n",
      "Epoch [40/100] - loss: 1.0657, val_accuracy: 0.4059\n",
      "Epoch [41/100] - loss: 1.0648, val_accuracy: 0.4059\n",
      "Epoch [42/100] - loss: 1.0639, val_accuracy: 0.4100\n",
      "Epoch [43/100] - loss: 1.0629, val_accuracy: 0.4142\n",
      "Epoch [44/100] - loss: 1.0619, val_accuracy: 0.4561\n",
      "Epoch [45/100] - loss: 1.0609, val_accuracy: 0.5063\n",
      "Epoch [46/100] - loss: 1.0598, val_accuracy: 0.5983\n",
      "Epoch [47/100] - loss: 1.0587, val_accuracy: 0.6360\n",
      "Epoch [48/100] - loss: 1.0576, val_accuracy: 0.6946\n",
      "Epoch [49/100] - loss: 1.0565, val_accuracy: 0.7197\n",
      "Epoch [50/100] - loss: 1.0553, val_accuracy: 0.7406\n",
      "Epoch [51/100] - loss: 1.0541, val_accuracy: 0.7406\n",
      "Epoch [52/100] - loss: 1.0528, val_accuracy: 0.7615\n",
      "Epoch [53/100] - loss: 1.0515, val_accuracy: 0.7741\n",
      "Epoch [54/100] - loss: 1.0502, val_accuracy: 0.7824\n",
      "Epoch [55/100] - loss: 1.0488, val_accuracy: 0.7866\n",
      "Epoch [56/100] - loss: 1.0474, val_accuracy: 0.7866\n",
      "Epoch [57/100] - loss: 1.0460, val_accuracy: 0.7866\n",
      "Epoch [58/100] - loss: 1.0445, val_accuracy: 0.7866\n",
      "Epoch [59/100] - loss: 1.0429, val_accuracy: 0.7866\n",
      "Epoch [60/100] - loss: 1.0413, val_accuracy: 0.7908\n",
      "Epoch [61/100] - loss: 1.0396, val_accuracy: 0.7908\n",
      "Epoch [62/100] - loss: 1.0379, val_accuracy: 0.7908\n",
      "Epoch [63/100] - loss: 1.0361, val_accuracy: 0.7908\n",
      "Epoch [64/100] - loss: 1.0343, val_accuracy: 0.7908\n",
      "Epoch [65/100] - loss: 1.0324, val_accuracy: 0.7908\n",
      "Epoch [66/100] - loss: 1.0305, val_accuracy: 0.7908\n",
      "Epoch [67/100] - loss: 1.0285, val_accuracy: 0.7908\n",
      "Epoch [68/100] - loss: 1.0264, val_accuracy: 0.7908\n",
      "Epoch [69/100] - loss: 1.0242, val_accuracy: 0.7908\n",
      "Epoch [70/100] - loss: 1.0220, val_accuracy: 0.7908\n",
      "Epoch [71/100] - loss: 1.0197, val_accuracy: 0.7908\n",
      "Epoch [72/100] - loss: 1.0174, val_accuracy: 0.7908\n",
      "Epoch [73/100] - loss: 1.0149, val_accuracy: 0.7908\n",
      "Epoch [74/100] - loss: 1.0124, val_accuracy: 0.7950\n",
      "Epoch [75/100] - loss: 1.0098, val_accuracy: 0.7950\n",
      "Epoch [76/100] - loss: 1.0071, val_accuracy: 0.7950\n",
      "Epoch [77/100] - loss: 1.0043, val_accuracy: 0.7950\n",
      "Epoch [78/100] - loss: 1.0015, val_accuracy: 0.7950\n",
      "Epoch [79/100] - loss: 0.9985, val_accuracy: 0.7950\n",
      "Epoch [80/100] - loss: 0.9955, val_accuracy: 0.7950\n",
      "Epoch [81/100] - loss: 0.9924, val_accuracy: 0.7950\n",
      "Epoch [82/100] - loss: 0.9892, val_accuracy: 0.7908\n",
      "Epoch [83/100] - loss: 0.9860, val_accuracy: 0.7908\n",
      "Epoch [84/100] - loss: 0.9826, val_accuracy: 0.7908\n",
      "Epoch [85/100] - loss: 0.9792, val_accuracy: 0.7908\n",
      "Epoch [86/100] - loss: 0.9757, val_accuracy: 0.7908\n",
      "Epoch [87/100] - loss: 0.9721, val_accuracy: 0.7908\n",
      "Epoch [88/100] - loss: 0.9685, val_accuracy: 0.7908\n",
      "Epoch [89/100] - loss: 0.9648, val_accuracy: 0.7908\n",
      "Epoch [90/100] - loss: 0.9610, val_accuracy: 0.7908\n",
      "Epoch [91/100] - loss: 0.9573, val_accuracy: 0.7908\n",
      "Epoch [92/100] - loss: 0.9534, val_accuracy: 0.7908\n",
      "Epoch [93/100] - loss: 0.9496, val_accuracy: 0.7908\n",
      "Epoch [94/100] - loss: 0.9457, val_accuracy: 0.7908\n",
      "Epoch [95/100] - loss: 0.9417, val_accuracy: 0.7908\n",
      "Epoch [96/100] - loss: 0.9378, val_accuracy: 0.7908\n",
      "Epoch [97/100] - loss: 0.9339, val_accuracy: 0.7908\n",
      "Epoch [98/100] - loss: 0.9299, val_accuracy: 0.7908\n",
      "Epoch [99/100] - loss: 0.9260, val_accuracy: 0.7908\n",
      "Epoch [100/100] - loss: 0.9221, val_accuracy: 0.7908\n",
      "Model saved: /tmp/tmpv6v8cgl2/model/001/model.pth\n"
     ]
    }
   ],
   "source": [
    "# Test preprocessing and training script combined.\n",
    "from preprocessor import preprocess\n",
    "# from train import train\n",
    "from train import train\n",
    "\n",
    "# Create a temporary directory to test the training.\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    # First, we preprocess the data and create the \n",
    "    # dataset splits.\n",
    "    preprocess(\n",
    "        base_directory=directory, \n",
    "        data_filepath=DATA_FILEPATH\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        base_directory=directory, \n",
    "        train_path=Path(directory) / \"train\", \n",
    "        validation_path=Path(directory) / \"validation\",\n",
    "        epochs=100,\n",
    "        learning_rate=0.01\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "038ff2e5-ed28-445b-bc03-4e996ec2286f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define tuning step\n",
    "objective_metric_name = \"val_accuracy\"\n",
    "objective_type = \"Maximize\"\n",
    "metric_definitions = [{\"Name\": objective_metric_name, \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"}]\n",
    "    \n",
    "hyperparameter_ranges = {\n",
    "    \"epochs\": IntegerParameter(10, 100),\n",
    "    \"batch_size\": IntegerParameter(8, 16),\n",
    "    \"learning_rate\": ContinuousParameter(0.007, 0.01),\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=f\"{CODE_FOLDER}/train.py\",\n",
    "    framework_version=\"1.8\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    py_version=\"py36\",\n",
    "    instance_count=1,\n",
    "    script_mode=True,\n",
    "    \n",
    "    # The default profiler rule includes a timestamp which will change each time\n",
    "    # the pipeline is upserted, causing cache misses. Since we don't need\n",
    "    # profiling, we can disable it to take advantage of caching.\n",
    "    disable_profiler=True,\n",
    "\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    objective_type=objective_type,\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cf5dd9a7-8643-4fbb-8eb4-40f39011e27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tune_model_step = TuningStep(\n",
    "    name = \"tune-model\",\n",
    "    tuner=tuner,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3ee3ab26-afa5-4ceb-9f7a-005d5fdea646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/evaluation.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "# from tensorflow import keras\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "MODEL_PATH = \"/opt/ml/processing/model/\"\n",
    "TEST_PATH = \"/opt/ml/processing/test/\"\n",
    "OUTPUT_PATH = \"/opt/ml/processing/evaluation/\"\n",
    "EVALUATION_NAME=\"evaluation\"\n",
    "\n",
    "# Had to repeat class here due to bug in using source_dir param in pytorch_processor.run\n",
    "class PenguinModel(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(PenguinModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=input_shape, out_features=10)\n",
    "        self.fc2 = nn.Linear(in_features=10, out_features=8)\n",
    "        self.fc3 = nn.Linear(in_features=8, out_features=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)  # Apply softmax along dimension 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "    # Prediction function\n",
    "    def predict(self, input_data):\n",
    "        input_data_torch = torch.tensor(input_data.values, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            self.eval()  # Set the model to evaluation mode\n",
    "            output = self(input_data_torch)        \n",
    "        return output\n",
    "    \n",
    "def evaluate(model_path, test_path, output_path, evaluation_name):\n",
    "    # The first step is to extract the model package so we can load \n",
    "    # it in memory.\n",
    "    with tarfile.open(Path(model_path) / \"model.tar.gz\") as tar:\n",
    "        tar.extractall(path=Path(model_path))\n",
    "        \n",
    "    X_test = pd.read_csv(Path(test_path) / \"test.csv\")\n",
    "    y_test = X_test[X_test.columns[-1]]\n",
    "    X_test.drop(X_test.columns[-1], axis=1, inplace=True)\n",
    "    \n",
    "    model = PenguinModel(X_test.shape[1])\n",
    "    model.load_state_dict(torch.load(Path(model_path) / \"001\" / \"model.pth\"))\n",
    "\n",
    "    predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, average='weighted')\n",
    "    recall = recall_score(y_test, predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, predictions, average='weighted')\n",
    "    num_samples = X_test.shape[0]\n",
    "    \n",
    "    # print(f\"Accuracy: {accuracy}. Precision: {precision}, Recall: {recall}, F1: {f1}, num_samples: {num_samples}\")\n",
    "\n",
    "    # Let's create an evaluation report using the model accuracy.\n",
    "    evaluation_report = {\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": {\n",
    "                \"value\": accuracy\n",
    "            },\n",
    "            \"Precision\": {\n",
    "                \"value\": precision\n",
    "            },\n",
    "            \"Recall\": {\n",
    "                \"value\": recall\n",
    "            },\n",
    "            \"F1\": {\n",
    "                \"value\": f1\n",
    "            },\n",
    "            \"num_samples\": {\n",
    "                \"value\": num_samples\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    print(evaluation_report)\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_path) / f\"{evaluation_name}.json\", \"w\") as f:\n",
    "        f.write(json.dumps(evaluation_report))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--evaluation_name', type=str, dest='evaluation_name', default=\"evaluation\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    evaluate(\n",
    "        model_path=MODEL_PATH, \n",
    "        test_path=TEST_PATH,\n",
    "        output_path=OUTPUT_PATH,\n",
    "        evaluation_name=args.evaluation_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9a2540d8-278a-4953-bc54-0469d154427d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - loss: 1.0899, val_accuracy: 0.4100\n",
      "Epoch [2/50] - loss: 1.0886, val_accuracy: 0.4100\n",
      "Epoch [3/50] - loss: 1.0873, val_accuracy: 0.4100\n",
      "Epoch [4/50] - loss: 1.0860, val_accuracy: 0.4100\n",
      "Epoch [5/50] - loss: 1.0846, val_accuracy: 0.4100\n",
      "Epoch [6/50] - loss: 1.0833, val_accuracy: 0.4100\n",
      "Epoch [7/50] - loss: 1.0819, val_accuracy: 0.4100\n",
      "Epoch [8/50] - loss: 1.0805, val_accuracy: 0.4100\n",
      "Epoch [9/50] - loss: 1.0791, val_accuracy: 0.4100\n",
      "Epoch [10/50] - loss: 1.0777, val_accuracy: 0.4100\n",
      "Epoch [11/50] - loss: 1.0762, val_accuracy: 0.4100\n",
      "Epoch [12/50] - loss: 1.0747, val_accuracy: 0.4100\n",
      "Epoch [13/50] - loss: 1.0732, val_accuracy: 0.4100\n",
      "Epoch [14/50] - loss: 1.0717, val_accuracy: 0.4100\n",
      "Epoch [15/50] - loss: 1.0701, val_accuracy: 0.4100\n",
      "Epoch [16/50] - loss: 1.0685, val_accuracy: 0.4100\n",
      "Epoch [17/50] - loss: 1.0669, val_accuracy: 0.4100\n",
      "Epoch [18/50] - loss: 1.0653, val_accuracy: 0.4100\n",
      "Epoch [19/50] - loss: 1.0636, val_accuracy: 0.4100\n",
      "Epoch [20/50] - loss: 1.0619, val_accuracy: 0.4100\n",
      "Epoch [21/50] - loss: 1.0602, val_accuracy: 0.4100\n",
      "Epoch [22/50] - loss: 1.0585, val_accuracy: 0.4100\n",
      "Epoch [23/50] - loss: 1.0567, val_accuracy: 0.4100\n",
      "Epoch [24/50] - loss: 1.0549, val_accuracy: 0.4100\n",
      "Epoch [25/50] - loss: 1.0531, val_accuracy: 0.4100\n",
      "Epoch [26/50] - loss: 1.0512, val_accuracy: 0.4100\n",
      "Epoch [27/50] - loss: 1.0493, val_accuracy: 0.4100\n",
      "Epoch [28/50] - loss: 1.0474, val_accuracy: 0.4100\n",
      "Epoch [29/50] - loss: 1.0455, val_accuracy: 0.4100\n",
      "Epoch [30/50] - loss: 1.0436, val_accuracy: 0.4100\n",
      "Epoch [31/50] - loss: 1.0416, val_accuracy: 0.4100\n",
      "Epoch [32/50] - loss: 1.0397, val_accuracy: 0.4100\n",
      "Epoch [33/50] - loss: 1.0377, val_accuracy: 0.4100\n",
      "Epoch [34/50] - loss: 1.0356, val_accuracy: 0.4100\n",
      "Epoch [35/50] - loss: 1.0336, val_accuracy: 0.4100\n",
      "Epoch [36/50] - loss: 1.0315, val_accuracy: 0.4100\n",
      "Epoch [37/50] - loss: 1.0295, val_accuracy: 0.4100\n",
      "Epoch [38/50] - loss: 1.0274, val_accuracy: 0.4100\n",
      "Epoch [39/50] - loss: 1.0254, val_accuracy: 0.4100\n",
      "Epoch [40/50] - loss: 1.0233, val_accuracy: 0.4100\n",
      "Epoch [41/50] - loss: 1.0212, val_accuracy: 0.4100\n",
      "Epoch [42/50] - loss: 1.0191, val_accuracy: 0.4100\n",
      "Epoch [43/50] - loss: 1.0170, val_accuracy: 0.4100\n",
      "Epoch [44/50] - loss: 1.0149, val_accuracy: 0.4100\n",
      "Epoch [45/50] - loss: 1.0128, val_accuracy: 0.4100\n",
      "Epoch [46/50] - loss: 1.0108, val_accuracy: 0.4100\n",
      "Epoch [47/50] - loss: 1.0087, val_accuracy: 0.4100\n",
      "Epoch [48/50] - loss: 1.0066, val_accuracy: 0.4100\n",
      "Epoch [49/50] - loss: 1.0046, val_accuracy: 0.4100\n",
      "Epoch [50/50] - loss: 1.0026, val_accuracy: 0.4100\n",
      "Model saved: /tmp/tmpxbs818th/model/001/model.pth\n",
      "{'metrics': {'accuracy': {'value': 0.5490196078431373}, 'Precision': {'value': 0.30142252979623224}, 'Recall': {'value': 0.5490196078431373}, 'F1': {'value': 0.3891784561926036}, 'num_samples': {'value': 51}}}\n",
      "{'metrics': {'accuracy': {'value': 0.5490196078431373}, 'Precision': {'value': 0.30142252979623224}, 'Recall': {'value': 0.5490196078431373}, 'F1': {'value': 0.3891784561926036}, 'num_samples': {'value': 51}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from preprocessor import preprocess\n",
    "from train import train\n",
    "from evaluation import evaluate\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    preprocess(\n",
    "        base_directory=directory, \n",
    "        data_filepath=DATA_FILEPATH\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        base_directory=directory, \n",
    "        train_path=Path(directory) / \"train\", \n",
    "        validation_path=Path(directory) / \"validation\",\n",
    "        epochs=50\n",
    "    )\n",
    "    \n",
    "    # After training a model, we need to prepare a package just like\n",
    "    # SageMaker would. This package is what the evaluation script is\n",
    "    # expecting as an input.\n",
    "    with tarfile.open(Path(directory) / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(Path(directory) / \"model\" / \"001\", arcname=\"001\")\n",
    "        \n",
    "    \n",
    "    # We can now call the evaluation script.\n",
    "    evaluate(\n",
    "        model_path=directory, \n",
    "        test_path=Path(directory) / \"test\",\n",
    "        output_path=Path(directory) / \"evaluation\",\n",
    "        evaluation_name=\"evaluation\",\n",
    "    )\n",
    "    \n",
    "    with open(Path(directory) / \"evaluation\" / f\"evaluation.json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "48139a07-5c8e-4bc6-b666-bf9531f7f520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    }
   ],
   "source": [
    "pytorch_processor = PyTorchProcessor(\n",
    "    base_job_name=\"penguins-evaluation-processor\",\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=PipelineSession(),\n",
    ")\n",
    "\n",
    "# This is a workaround to a problem with the SageMaker SDK: \n",
    "# By default, the TensorFlowProcessor runs the script using\n",
    "# /bin/bash as its entrypoint. We want to ensure we run it \n",
    "# using python3.\n",
    "pytorch_processor.framework_entrypoint_command = [\"python3\"]\n",
    "\n",
    "eval_winner_name = \"evaluate-winner-model\"\n",
    "\n",
    "# We want to map the evaluation report that we generate inside\n",
    "# the evaluation script so we can later reference it.\n",
    "def create_eval_report(report_name):\n",
    "    return PropertyFile(\n",
    "        name=report_name,\n",
    "        output_name=\"evaluation\",\n",
    "        path=f\"{report_name}.json\",\n",
    "    )\n",
    "\n",
    "def create_eval_process_step(evaluation_name, report, top_k=0):\n",
    "    return ProcessingStep(\n",
    "        name=evaluation_name,\n",
    "        processor=pytorch_processor,\n",
    "        inputs=[\n",
    "            ProcessingInput(source=preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\"\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=(\n",
    "                    tune_model_step.get_top_model_s3_uri(top_k=top_k, s3_bucket=sagemaker_session.default_bucket()) \n",
    "                ),\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\", destination=f\"{S3_LOCATION}/evaluation\"),\n",
    "        ],\n",
    "        code=f'{CODE_FOLDER}/evaluation.py',\n",
    "        job_arguments=[\"--evaluation_name\", evaluation_name],\n",
    "        property_files=[report],\n",
    "        cache_config=cache_config,\n",
    "    )\n",
    "    \n",
    "eval_winner_report = create_eval_report(eval_winner_name)\n",
    "\n",
    "eval_model_step = create_eval_process_step(eval_winner_name, \n",
    "                                        eval_winner_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4982146f-0c0f-4938-b5d0-06db45a58531",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(on=\"/\", values=[\n",
    "            eval_model_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri'], f\"{eval_winner_name}.json\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "model_package_group_name = \"penguins\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "52a48cef-fb78-412b-a5c6-977eafe98e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py:297: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def get_model(top_k=0):\n",
    "    return PyTorchModel(\n",
    "        model_data=(\n",
    "            tune_model_step.get_top_model_s3_uri(top_k, s3_bucket=PipelineSession().default_bucket())\n",
    "        ),\n",
    "        framework_version=\"1.8\",\n",
    "        py_version=\"py36\",\n",
    "        sagemaker_session=PipelineSession(),\n",
    "        role=role,\n",
    "    )\n",
    "\n",
    "def model_registry_args(model,\n",
    "                        model_metrics, \n",
    "                        approval_status=\"PendingManualApproval\"):\n",
    "    return model.register(\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        model_metrics=model_metrics,\n",
    "        approval_status=approval_status,\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"text/csv\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        transform_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"PYTORCH\",\n",
    "        framework_version=\"1.8\",\n",
    "    )\n",
    "\n",
    "model = get_model() \n",
    "\n",
    "args_approved = model_registry_args(model, \n",
    "                                    model_metrics, \n",
    "                                    \"Approved\")\n",
    "\n",
    "args_pending = model_registry_args(model,\n",
    "                                model_metrics)\n",
    "\n",
    "register_step_approved = ModelStep(\n",
    "    name=\"register-model-approved\",\n",
    "    step_args=args_approved,\n",
    ")\n",
    "\n",
    "register_step_pending = ModelStep(\n",
    "    name=\"register-model-pending-approval\",\n",
    "    step_args=args_pending,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "36e2a2b1-6711-4266-95d8-d2aebd52e199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_threshold = ParameterFloat(\n",
    "    name=\"accuracy_threshold\", \n",
    "    default_value=0.70\n",
    ")\n",
    "\n",
    "min_accuracy_threshold = ParameterFloat(\n",
    "    name=\"accuracy_threshold_min\", \n",
    "    default_value=0.50\n",
    ")\n",
    "\n",
    "def gte_eval_condition(step, report, accuracy):\n",
    "    return ConditionGreaterThanOrEqualTo(\n",
    "        left=JsonGet(\n",
    "            step_name=step.name,\n",
    "            property_file=report,\n",
    "            json_path=\"metrics.accuracy.value\"\n",
    "        ),\n",
    "        right=accuracy\n",
    "    )\n",
    "\n",
    "def lte_eval_condition(step, report, accuracy):\n",
    "    return ConditionLessThanOrEqualTo(\n",
    "        left=JsonGet(\n",
    "            step_name=step.name,\n",
    "            property_file=report,\n",
    "            json_path=\"metrics.accuracy.value\"\n",
    "        ),\n",
    "        right=accuracy\n",
    "    )\n",
    "\n",
    "\n",
    "gte_approved = gte_eval_condition(eval_model_step, \n",
    "                                eval_winner_report,\n",
    "                                accuracy_threshold)\n",
    "\n",
    "lte_min = lte_eval_condition(eval_model_step,\n",
    "                            eval_winner_report,\n",
    "                            min_accuracy_threshold)\n",
    "\n",
    "\n",
    "gte_min = gte_eval_condition(eval_model_step,\n",
    "                            eval_winner_report,\n",
    "                            min_accuracy_threshold)\n",
    "\n",
    "lte_approved = lte_eval_condition(eval_model_step,\n",
    "                               eval_winner_report,\n",
    "                               accuracy_threshold)\n",
    "\n",
    "fail_step_min = FailStep(\n",
    "    name=\"fail-min\",\n",
    "    error_message=Join(\n",
    "        on=\" \", \n",
    "        values=[\n",
    "            \"Execution failed because the model's accuracy was lower than\", \n",
    "            min_accuracy_threshold\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "def create_condition_step(name, conditions, if_steps, else_steps=None):\n",
    "    return ConditionStep(\n",
    "        name=name,\n",
    "        conditions=conditions,\n",
    "        if_steps=if_steps,\n",
    "        else_steps=else_steps\n",
    "    )\n",
    "\n",
    "# evaluate_tune_min = create_condition_step(\"check-min-accuracy\", [condition_pending_approval_winner, condition_pending_approval_second],[fail_step_min])\n",
    "\n",
    "check_min_step = create_condition_step(\"min-model-accuracy\",\n",
    "                                        [lte_min],\n",
    "                                        [fail_step_min],)\n",
    "\n",
    "approved_step = create_condition_step(\"approved-model-accuracy\", \n",
    "                                        [gte_approved],\n",
    "                                        [register_step_approved])\n",
    "pending_step = create_condition_step(\"pending-model-accuracy\",\n",
    "                                        [lte_approved, gte_min],\n",
    "                                        [register_step_pending],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f70bcd33-b499-4e2b-953e-94d1ed96c10a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:eu-north-1:253909639528:pipeline/penguins-best-model-pipeline/execution/s23chs0r9o8i', sagemaker_session=<sagemaker.session.Session object at 0x7f4ec4698c10>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"penguins-best-model-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        accuracy_threshold,\n",
    "        min_accuracy_threshold,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_data_step, \n",
    "        tune_model_step,\n",
    "        eval_model_step,\n",
    "        check_min_step,\n",
    "        approved_step,\n",
    "        pending_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config\n",
    ")\n",
    "# pipeline.delete()\n",
    "pipeline.upsert(role_arn=role)\n",
    "pipeline.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8d585140-7940-4543-9954-b74352e8ff3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.workflow.lambda_step import LambdaStep, LambdaOutput, LambdaOutputTypeEnum\n",
    "from sagemaker.workflow.parameters import ParameterBoolean\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.s3 import S3Downloader\n",
    "from sagemaker.workflow.parameters import ParameterInteger\n",
    "from sagemaker import ModelPackage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ac9cec59-c812-4ca9-9f71-d6725de03c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./code/endpoint'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENDPOINT_CODE_FOLDER = CODE_FOLDER / \"endpoint\"\n",
    "Path(ENDPOINT_CODE_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "sys.path.append\n",
    "(f\"./{ENDPOINT_CODE_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a34c1c1-66af-4cf2-b103-8612bd60ce0e",
   "metadata": {},
   "source": [
    "We will include the inference code as part of the model assets to control the inference process on the SageMaker endpoint. SageMaker will automatically call the `handler()` function for every request to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "57e7ad9e-598b-4e28-9a20-a93ad2bb5f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/endpoint/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {ENDPOINT_CODE_FOLDER}/inference.py\n",
    "\n",
    "from model import PenguinModel\n",
    "\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pickle import load\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def _get_pipeline(directory=None):\n",
    "    \"\"\"\n",
    "    This function returns the Scikit-Learn pipeline we used to transform the\n",
    "    dataset.\n",
    "    \"\"\"\n",
    "    if(directory is None):\n",
    "        directory = os.environ(\"PREPROCESSING_DIR\", \"/tmp\")\n",
    "        \n",
    "    pipeline_file = Path(directory) / \"pipeline\" / \"pipeline.pkl\"\n",
    "    \n",
    "    _download(pipeline_file)\n",
    "    \n",
    "    return load(open(pipeline_file, 'rb'))\n",
    "\n",
    "def _get_class(prediction, directory):\n",
    "    \"\"\"\n",
    "    This function returns the class name of a given prediction. \n",
    "    \"\"\"\n",
    "    classes_file = Path(directory) / \"pipeline\" / \"classes.csv\"\n",
    "    _download(classes_file)\n",
    "    \n",
    "    with open(classes_file) as f:\n",
    "        file = f.readlines()\n",
    "        \n",
    "    classes = list(map(lambda x: x.replace(\"'\", \"\"), file[0].split(',')))\n",
    "    return classes[prediction]\n",
    "\n",
    "def _download(file):\n",
    "    \"\"\"\n",
    "    This function will download a file from S3 if it doesn't already exist. The\n",
    "    function will use the `S3_LOCATION` environment variable to determine the\n",
    "    location of the file.\n",
    "    \"\"\"\n",
    "    if(file.exists()):\n",
    "        return\n",
    "    \n",
    "    s3_uri = os.environ.get(\"S3_LOCATION\", f\"s3://vmate-mlschool4/penguins/preprocessing\")\n",
    "        \n",
    "    s3_parts = s3_uri.split('/', 3)\n",
    "    bucket = s3_parts[2]\n",
    "    key = s3_parts[3]\n",
    "    \n",
    "    s3.Bucket(bucket).download_file(f\"{key}/{file.name}\", str(file))   \n",
    "    \n",
    "def _process_probabilities(probabilities):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    prediction = np.argmax(probabilities)\n",
    "    confidence = probabilities[prediction]\n",
    "    return prediction, confidence\n",
    "    \n",
    "def _process_prediction(prediction, confidence, directory=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"    \n",
    "    return {\n",
    "        \"species\": _get_class(prediction, directory),\n",
    "        \"prediction\": int(prediction),\n",
    "        \"confidence\": confidence.item()\n",
    "    }   \n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Loading model ...\")\n",
    "    input_shape = 7\n",
    "    \n",
    "    model = PenguinModel(input_shape=input_shape)\n",
    "    with open(Path(model_dir) / \"model\" / \"001\" / 'model.pth', 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "        \n",
    "    for key, value in os.environ.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def input_fn(request_body, request_content_type, directory=None):\n",
    "    \"\"\"\n",
    "    \"\"\"    \n",
    "    print(f\"Processing input data...\")\n",
    "    \n",
    "    if request_content_type in (\"application/json\", \"application/octet-stream\"):\n",
    "        # When the endpoint is running, we will receive a context\n",
    "        # object. We need to parse the input and turn it into \n",
    "        # JSON in that case.\n",
    "        endpoint_input = json.loads(request_body)\n",
    "\n",
    "        if endpoint_input is None:\n",
    "            raise ValueError(\"There was an error parsing the input request.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {context.request_content_type or 'unknown'}\")\n",
    "        \n",
    "    pipeline = _get_pipeline(directory)    \n",
    "    df = pd.json_normalize(endpoint_input)\n",
    "    result = pipeline.transform(df)\n",
    "    result = pd.DataFrame(result)\n",
    "    \n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Sending input data to model to make a prediction...\")\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model.predict(input_data)\n",
    "    return out\n",
    "    \n",
    "def output_fn(predictions, directory=None, accept=\"application/json\"):\n",
    "    \"\"\"\n",
    "    \"\"\"    \n",
    "    print(\"Processing prediction received from the model...\")\n",
    "    \n",
    "    results = list(map(_process_probabilities, predictions))\n",
    "    print(results)\n",
    "    predictions = list(map(lambda result: _process_prediction(result[0],result[1], directory), results))\n",
    "\n",
    "    if accept == 'application/json':\n",
    "        return json.dumps(predictions), accept\n",
    "    raise Exception(f'Requested unsupported ContentType in Accept:{accept}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "13b4530a-5349-46eb-ad44-675fe50f3446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - loss: 1.0838, val_accuracy: 0.4310\n",
      "Epoch [2/50] - loss: 1.0833, val_accuracy: 0.4310\n",
      "Epoch [3/50] - loss: 1.0827, val_accuracy: 0.4310\n",
      "Epoch [4/50] - loss: 1.0822, val_accuracy: 0.4310\n",
      "Epoch [5/50] - loss: 1.0817, val_accuracy: 0.4310\n",
      "Epoch [6/50] - loss: 1.0812, val_accuracy: 0.4310\n",
      "Epoch [7/50] - loss: 1.0807, val_accuracy: 0.4310\n",
      "Epoch [8/50] - loss: 1.0803, val_accuracy: 0.4310\n",
      "Epoch [9/50] - loss: 1.0798, val_accuracy: 0.4310\n",
      "Epoch [10/50] - loss: 1.0793, val_accuracy: 0.4310\n",
      "Epoch [11/50] - loss: 1.0788, val_accuracy: 0.4310\n",
      "Epoch [12/50] - loss: 1.0783, val_accuracy: 0.4310\n",
      "Epoch [13/50] - loss: 1.0778, val_accuracy: 0.4310\n",
      "Epoch [14/50] - loss: 1.0773, val_accuracy: 0.4310\n",
      "Epoch [15/50] - loss: 1.0768, val_accuracy: 0.4310\n",
      "Epoch [16/50] - loss: 1.0764, val_accuracy: 0.4310\n",
      "Epoch [17/50] - loss: 1.0759, val_accuracy: 0.4310\n",
      "Epoch [18/50] - loss: 1.0754, val_accuracy: 0.4310\n",
      "Epoch [19/50] - loss: 1.0749, val_accuracy: 0.4310\n",
      "Epoch [20/50] - loss: 1.0744, val_accuracy: 0.4310\n",
      "Epoch [21/50] - loss: 1.0740, val_accuracy: 0.4310\n",
      "Epoch [22/50] - loss: 1.0735, val_accuracy: 0.4310\n",
      "Epoch [23/50] - loss: 1.0730, val_accuracy: 0.4310\n",
      "Epoch [24/50] - loss: 1.0725, val_accuracy: 0.4310\n",
      "Epoch [25/50] - loss: 1.0720, val_accuracy: 0.4310\n",
      "Epoch [26/50] - loss: 1.0715, val_accuracy: 0.4310\n",
      "Epoch [27/50] - loss: 1.0710, val_accuracy: 0.4310\n",
      "Epoch [28/50] - loss: 1.0705, val_accuracy: 0.4310\n",
      "Epoch [29/50] - loss: 1.0701, val_accuracy: 0.4310\n",
      "Epoch [30/50] - loss: 1.0696, val_accuracy: 0.4310\n",
      "Epoch [31/50] - loss: 1.0691, val_accuracy: 0.4310\n",
      "Epoch [32/50] - loss: 1.0686, val_accuracy: 0.4310\n",
      "Epoch [33/50] - loss: 1.0680, val_accuracy: 0.4310\n",
      "Epoch [34/50] - loss: 1.0675, val_accuracy: 0.4310\n",
      "Epoch [35/50] - loss: 1.0670, val_accuracy: 0.4310\n",
      "Epoch [36/50] - loss: 1.0665, val_accuracy: 0.4310\n",
      "Epoch [37/50] - loss: 1.0660, val_accuracy: 0.4310\n",
      "Epoch [38/50] - loss: 1.0654, val_accuracy: 0.4310\n",
      "Epoch [39/50] - loss: 1.0649, val_accuracy: 0.4310\n",
      "Epoch [40/50] - loss: 1.0644, val_accuracy: 0.4310\n",
      "Epoch [41/50] - loss: 1.0638, val_accuracy: 0.4310\n",
      "Epoch [42/50] - loss: 1.0633, val_accuracy: 0.4310\n",
      "Epoch [43/50] - loss: 1.0627, val_accuracy: 0.4310\n",
      "Epoch [44/50] - loss: 1.0622, val_accuracy: 0.4310\n",
      "Epoch [45/50] - loss: 1.0616, val_accuracy: 0.4310\n",
      "Epoch [46/50] - loss: 1.0610, val_accuracy: 0.4310\n",
      "Epoch [47/50] - loss: 1.0604, val_accuracy: 0.4310\n",
      "Epoch [48/50] - loss: 1.0598, val_accuracy: 0.4310\n",
      "Epoch [49/50] - loss: 1.0592, val_accuracy: 0.4310\n",
      "Epoch [50/50] - loss: 1.0586, val_accuracy: 0.4310\n",
      "Model saved: /tmp/tmps76p44cy/model/001/model.pth\n",
      "Loading model ...\n",
      "PYTHONIOENCODING: UTF-8\n",
      "REGION_NAME: eu-north-1\n",
      "HOSTNAME: pytorch-1-10-cpu-py38-ml-t3-medium-8265974f1f54da4fb1fd6ac71882\n",
      "LD_LIBRARY_PATH: :/usr/local/lib:/opt/conda/lib:/home/.openmpi/lib/\n",
      "HOME: /root\n",
      "PYTHONUNBUFFERED: 1\n",
      "AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /_sagemaker-instance-credentials/f29df86a023b91eeaefa47997224f6aa52d6568df4026f45b2f05601bbc93088\n",
      "PYTHONNOUSERSITE: 0\n",
      "PYTHONDONTWRITEBYTECODE: 1\n",
      "AWS_DEFAULT_REGION: eu-north-1\n",
      "PATH: /opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/.openmpi/bin:/tmp/miniconda3/condabin:/tmp/anaconda3/condabin:/tmp/miniconda2/condabin:/tmp/anaconda2/condabin:/tmp/mambaforge/condabin\n",
      "LANG: C.UTF-8\n",
      "AWS_ACCOUNT_ID: 253909639528\n",
      "AWS_REGION: eu-north-1\n",
      "AWS_INTERNAL_IMAGE_OWNER: DLC\n",
      "DLC_CONTAINER_TYPE: training\n",
      "LC_ALL: C.UTF-8\n",
      "PWD: /root\n",
      "SAGEMAKER_TRAINING_MODULE: sagemaker_pytorch_container.training:main\n",
      "AWS_SAGEMAKER_PYTHONNOUSERSITE: 0\n",
      "SAGEMAKER_LOG_FILE: /var/log/studio/kernel_gateway.log\n",
      "SAGEMAKER_INTERNAL_IMAGE_URI: 763104351884.dkr.ecr.eu-north-1.amazonaws.com/pytorch-training@sha256:d015b667dea73422be80779560f6edf28726310e6f0ac5d15d489cb80056072d\n",
      "JUPYTER_PATH: /opt/conda/share/jupyter/\n",
      "KERNEL_LAUNCH_TIMEOUT: 40\n",
      "KERNEL_WORKING_PATH: ml.school/penguins\n",
      "KERNEL_GATEWAY: 1\n",
      "JPY_PARENT_PID: 16\n",
      "TERM: xterm-color\n",
      "CLICOLOR: 1\n",
      "PAGER: cat\n",
      "GIT_PAGER: cat\n",
      "MPLBACKEND: module://ipykernel.pylab.backend_inline\n",
      "KMP_DUPLICATE_LIB_OK: True\n",
      "KMP_INIT_AT_FORK: FALSE\n",
      "Processing input data...\n",
      "Sending input data to model to make a prediction...\n",
      "Processing prediction received from the model...\n",
      "[(tensor(0), tensor(0.4594))]\n",
      "Loading model ...\n",
      "PYTHONIOENCODING: UTF-8\n",
      "REGION_NAME: eu-north-1\n",
      "HOSTNAME: pytorch-1-10-cpu-py38-ml-t3-medium-8265974f1f54da4fb1fd6ac71882\n",
      "LD_LIBRARY_PATH: :/usr/local/lib:/opt/conda/lib:/home/.openmpi/lib/\n",
      "HOME: /root\n",
      "PYTHONUNBUFFERED: 1\n",
      "AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /_sagemaker-instance-credentials/f29df86a023b91eeaefa47997224f6aa52d6568df4026f45b2f05601bbc93088\n",
      "PYTHONNOUSERSITE: 0\n",
      "PYTHONDONTWRITEBYTECODE: 1\n",
      "AWS_DEFAULT_REGION: eu-north-1\n",
      "PATH: /opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/.openmpi/bin:/tmp/miniconda3/condabin:/tmp/anaconda3/condabin:/tmp/miniconda2/condabin:/tmp/anaconda2/condabin:/tmp/mambaforge/condabin\n",
      "LANG: C.UTF-8\n",
      "AWS_ACCOUNT_ID: 253909639528\n",
      "AWS_REGION: eu-north-1\n",
      "AWS_INTERNAL_IMAGE_OWNER: DLC\n",
      "DLC_CONTAINER_TYPE: training\n",
      "LC_ALL: C.UTF-8\n",
      "PWD: /root\n",
      "SAGEMAKER_TRAINING_MODULE: sagemaker_pytorch_container.training:main\n",
      "AWS_SAGEMAKER_PYTHONNOUSERSITE: 0\n",
      "SAGEMAKER_LOG_FILE: /var/log/studio/kernel_gateway.log\n",
      "SAGEMAKER_INTERNAL_IMAGE_URI: 763104351884.dkr.ecr.eu-north-1.amazonaws.com/pytorch-training@sha256:d015b667dea73422be80779560f6edf28726310e6f0ac5d15d489cb80056072d\n",
      "JUPYTER_PATH: /opt/conda/share/jupyter/\n",
      "KERNEL_LAUNCH_TIMEOUT: 40\n",
      "KERNEL_WORKING_PATH: ml.school/penguins\n",
      "KERNEL_GATEWAY: 1\n",
      "JPY_PARENT_PID: 16\n",
      "TERM: xterm-color\n",
      "CLICOLOR: 1\n",
      "PAGER: cat\n",
      "GIT_PAGER: cat\n",
      "MPLBACKEND: module://ipykernel.pylab.backend_inline\n",
      "KMP_DUPLICATE_LIB_OK: True\n",
      "KMP_INIT_AT_FORK: FALSE\n",
      "Processing input data...\n",
      "Sending input data to model to make a prediction...\n",
      "Processing prediction received from the model...\n",
      "[(tensor(0), tensor(0.4594))]\n"
     ]
    }
   ],
   "source": [
    "#  Test inference code\n",
    "from preprocessor import preprocess\n",
    "from endpoint.inference import *\n",
    "import json \n",
    "\n",
    "samples = [\n",
    "    {\n",
    "        \"island\": \"Biscoe\",\n",
    "        \"culmen_length_mm\": 48.6,\n",
    "        \"culmen_depth_mm\": 16.0,\n",
    "        \"flipper_length_mm\": 230.0,\n",
    "        \"body_mass_g\": 5800.0,\n",
    "    },\n",
    "    {\n",
    "        \"island\": \"Biscoe\",\n",
    "        \"culmen_length_mm\": 48.6,\n",
    "        \"culmen_depth_mm\": 16.0,\n",
    "        \"flipper_length_mm\": 230.0,\n",
    "        \"body_mass_g\": 5800.0,\n",
    "    }\n",
    "]\n",
    "\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    \n",
    "    preprocess(\n",
    "        base_directory=directory, \n",
    "        data_filepath=DATA_FILEPATH\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        base_directory=directory, \n",
    "        train_path=Path(directory) / \"train\", \n",
    "        validation_path=Path(directory) / \"validation\",\n",
    "        epochs=50\n",
    "    )\n",
    "    \n",
    "    request_content_type = \"application/json\"\n",
    "    \n",
    "    for sample in samples:\n",
    "        model = model_fn(Path(directory))\n",
    "        transformed_list = input_fn(json.dumps(sample), request_content_type, directory)\n",
    "        output_np = predict_fn(transformed_list, model)\n",
    "        predictions = output_fn(output_np,directory)\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e2c6d-977e-43ec-98d4-ec66781af582",
   "metadata": {},
   "source": [
    "SageMaker's default TensorFlow inference container doesn't come with Scikit-Learn installed, so we need to provide a `requirements.txt` file with the libraries we want SageMaker to install in our endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ed40d098-d553-4d56-b2eb-f80cec420ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/endpoint/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {ENDPOINT_CODE_FOLDER}/requirements.txt\n",
    "\n",
    "numpy==1.19.5\n",
    "pandas==1.1.5\n",
    "scikit-learn==0.23.2\n",
    "boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "afa8f28e-29fe-4694-815c-bc5fed19feec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py:297: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# response = sagemaker_client.list_model_packages(\n",
    "#     ModelPackageGroupName=MODEL_PACKAGE_GROUP,\n",
    "#     ModelApprovalStatus=\"Approved\",\n",
    "#     SortBy=\"CreationTime\",\n",
    "#     MaxResults=1,\n",
    "# )\n",
    "\n",
    "# package = response[\"ModelPackageSummaryList\"][0] if response[\"ModelPackageSummaryList\"] else None\n",
    "# package\n",
    "\n",
    "\n",
    "# model_package = ModelPackage(\n",
    "#     model_package_arn=package[\"ModelPackageArn\"], \n",
    "#     sagemaker_session=sagemaker_session,\n",
    "#     role=role, \n",
    "# )\n",
    "\n",
    "repacked_model = PyTorchModel(\n",
    "    name=\"penguins\",\n",
    "    model_data=(\n",
    "        tune_model_step.get_top_model_s3_uri(top_k=0, s3_bucket=PipelineSession().default_bucket())\n",
    "    ),\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    sagemaker_session=PipelineSession(),\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=str(ENDPOINT_CODE_FOLDER),\n",
    "    env={\n",
    "        \"PIPELINE_S3_LOCATION\": Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\"pipeline\"].S3Output.S3Uri,\n",
    "                \"pipeline.pkl\",\n",
    "            ]\n",
    "        ),\n",
    "        \"CLASSES_S3_LOCATION\": Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\"classes\"].S3Output.S3Uri,\n",
    "                \"classes.csv\",\n",
    "            ]\n",
    "        )\n",
    "    }    \n",
    ")\n",
    "\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name=\"register\",\n",
    "    display_name=\"register-model\",\n",
    "    step_args=repacked_model.register(\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        approval_status=\"Approved\",\n",
    "        content_types=[\"application/json\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"PYTORCH\",\n",
    "        framework_version=\"1.8\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "28c75afd-d0d0-47f4-b7b6-9d590c5b600e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/lambda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/lambda.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    model_package_arn = event[\"model_package_arn\"]\n",
    "    endpoint_name = event[\"endpoint_name\"]\n",
    "    data_capture_percentage = event[\"data_capture_percentage\"]\n",
    "    data_capture_destination = event[\"data_capture_destination\"]\n",
    "    role = event[\"role\"]\n",
    "    \n",
    "    timestamp = time.strftime(\"%m%d%H%M%S\", time.localtime())\n",
    "    model_name = f\"penguins-model-{timestamp}\"\n",
    "    endpoint_config_name = f\"penguins-endpoint-config-{timestamp}\"\n",
    "\n",
    "    sagemaker.create_model(\n",
    "        ModelName=model_name, \n",
    "        ExecutionRoleArn=role, \n",
    "        Containers=[{\n",
    "            \"ModelPackageName\": model_package_arn\n",
    "        }] \n",
    "    )\n",
    "\n",
    "    sagemaker.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"ModelName\": model_name,\n",
    "                \"InstanceType\": \"ml.m5.large\",\n",
    "                \"InitialVariantWeight\": 1,\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "            }\n",
    "        ],\n",
    "        DataCaptureConfig={\n",
    "            \"EnableCapture\": True,\n",
    "            \"InitialSamplingPercentage\": data_capture_percentage,\n",
    "            \"DestinationS3Uri\": data_capture_destination,\n",
    "            \"CaptureOptions\": [\n",
    "                {\n",
    "                    'CaptureMode': \"Input\"\n",
    "                },\n",
    "                {\n",
    "                    'CaptureMode': \"Output\"\n",
    "                },\n",
    "            ],\n",
    "            \"CaptureContentTypeHeader\": {\n",
    "                \"JsonContentTypes\": [\n",
    "                    \"application/json\",\n",
    "                    \"application/octect-stream\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    sagemaker.create_endpoint(\n",
    "        EndpointName=endpoint_name, \n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps(\"Endpoint deployed successfully\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f9941979-c085-4ef9-8c66-908378d89a91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lambda_role(role_name):\n",
    "    try:\n",
    "        response = iam_client.create_role(\n",
    "            RoleName = role_name,\n",
    "            AssumeRolePolicyDocument = json.dumps({\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\n",
    "                            \"Service\": \"lambda.amazonaws.com\"\n",
    "                        },\n",
    "                        \"Action\": \"sts:AssumeRole\"\n",
    "                    }\n",
    "                ]\n",
    "            }),\n",
    "            Description=\"Lambda Pipeline Role\"\n",
    "        )\n",
    "\n",
    "        role_arn = response['Role']['Arn']\n",
    "\n",
    "        iam_client.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
    "        )\n",
    "\n",
    "        iam_client.attach_role_policy(\n",
    "            PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess',\n",
    "            RoleName=role_name\n",
    "        )\n",
    "\n",
    "        return role_arn\n",
    "\n",
    "    except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "        response = iam_client.get_role(RoleName=role_name)\n",
    "        return response['Role']['Arn']\n",
    "\n",
    "\n",
    "lambda_role = create_lambda_role(\"lambda-pipeline-role\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7c6eda89-70f3-49b4-8983-90f4db72fd02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_capture_percentage = ParameterInteger(\n",
    "    name=\"data_capture_percentage\",\n",
    "    default_value=100,\n",
    ")\n",
    "\n",
    "data_capture_destination = ParameterString(\n",
    "    name=\"data_capture_destination\",\n",
    "    default_value=f\"{S3_LOCATION}/monitoring/data-capture\",\n",
    ")\n",
    "\n",
    "deploy_fn = Lambda(\n",
    "    function_name=\"deploy_fn\",\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=str(CODE_FOLDER / \"lambda.py\"),\n",
    "    handler=\"lambda.lambda_handler\",\n",
    "    timeout=600\n",
    ")\n",
    "\n",
    "deploy_fn.upsert()\n",
    "\n",
    "# print(register_model_step.properties)\n",
    "deploy_step = LambdaStep(\n",
    "    name=\"deploy\",\n",
    "    lambda_func=deploy_fn,\n",
    "    inputs={\n",
    "        # We use the ARN of the model we registered to\n",
    "        # deploy it to the endpoint.\n",
    "        \"model_package_arn\": register_model_step.properties.ModelPackageArn,\n",
    "\n",
    "        \"endpoint_name\": \"penguins-endpoint\",\n",
    "        \n",
    "        \"data_capture_percentage\": data_capture_percentage,\n",
    "        \"data_capture_destination\": data_capture_destination,\n",
    "        \n",
    "        \"role\": role,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "78b8983a-52de-46c5-8ffb-202090b4e10d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We'll send this payload to the endpoint. Notice how each line contains\n",
    "# the information of a penguin. The endpoint will return the predictions\n",
    "# for each of these lines.\n",
    "# payload = \"\"\"\n",
    "# 0.6569590202313976, -1.0813829646495108, 1.2097102831892812, 0.9226343641317372, 1.0, 0.0, 0.0\n",
    "# -0.7751048801481084, 0.8822689351285553,  -1.2168066120762704, 0.9226343641317372, 0.0, 1.0, 0.0\n",
    "# -0.837387834894918, 0.3386660813829646, -0.26237731892812, -1.92351941317372, 0.0, 0.0, 1.0\n",
    "# \"\"\"\n",
    "\n",
    "# We can now send the request to the endpoint and process the response.\n",
    "# predictor = Predictor(endpoint_name=ENDPOINT)\n",
    "# predictor.delete_endpoint()\n",
    "# response = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "# response = json.loads(response.decode(\"utf-8\"))\n",
    "\n",
    "# print(json.dumps(response, indent=2))\n",
    "# print(f\"\\nSpecies: {np.argmax(response['predictions'], axis=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544ae36-00b3-4bde-b133-c3a59bb7f1d8",
   "metadata": {},
   "source": [
    "# Session 5 - Data Monitoring\n",
    "\n",
    "In this session we'll set up a monitoring process to analyze the quality of the data our endpoint receives in production. For this, we will have SageMaker capture and evaluate the data observed by the endpoint.\n",
    "\n",
    "To enable this functionality, we need a couple of steps:\n",
    "\n",
    "1. Create a baseline to compare the real-time traffic.\n",
    "2. Set up a schedule to continuously evaluate and compare against the baseline.\n",
    "\n",
    "Notice that the Data Quality process uses the baseline dataset we generated during preprocessing. This baseline dataset is the same unprocessed train set in JSON format. We do this because we transformed the train data during the preprocessing step, but we need raw data because that's what the endpoint expects.\n",
    "\n",
    "Check [Amazon SageMaker Model Monitor](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.html) for a brief explanation of how to use SageMaker's Model Monitoring functionality. [Monitor models for data and model quality, bias, and explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) is a much more extensive guide to monitoring in Amazon SageMaker.\n",
    "\n",
    "Here is what the Pipeline will look like at the end of this session:\n",
    "\n",
    "<img src='images/session5-pipeline.png' alt='Session 5 Pipeline' width=\"600\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2c7e2f9d-cc75-46bc-8700-f7123292fac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "from IPython.display import JSON\n",
    "\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.quality_check_step import DataQualityCheckConfig, QualityCheckStep\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "from sagemaker.workflow.parameters import ParameterBoolean\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "\n",
    "DATA_QUALITY_LOCATION = f\"{S3_LOCATION}/monitoring/data-quality\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1e7af-933e-492d-948e-aa16cc67c3db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1 - Checking Captured Data\n",
    "\n",
    "Let's check the S3 location where the endpoint stores the requests and responses that it receives.\n",
    "\n",
    "Notice that it make take a few minutes for the first few files to show up in S3. Keep running the following line until you get some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3f35e8db-24d7-4d4b-9264-78ee5070cf27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = S3Downloader.list(data_capture_destination.default_value)[:3]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bc31d3-a277-446a-afd1-8bf7aab6173e",
   "metadata": {},
   "source": [
    "These files contain the data captured by the endpoint in a SageMaker-specific JSON-line format. Each inference request is captured in a single line in the `jsonl` file. The line contains both the input and output merged together.\n",
    "\n",
    "Let's read the first line from the first file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3dee0107-c9ca-4f75-873d-d47512c56797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(files):\n",
    "    lines = S3Downloader.read_file(files[0])\n",
    "    print(json.dumps(json.loads(lines.split(\"\\n\")[0]), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c26ac4-5d30-41e9-8952-e4deb39de819",
   "metadata": {},
   "source": [
    "## Step 2 - Generating a Baseline\n",
    "\n",
    "Let's now configure the [Quality Check Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) and feed it the train set we generated in the preprocessing step.\n",
    "\n",
    "We can configure the instance that will run the quality check using the [CheckJobConfig](https://sagemaker.readthedocs.io/en/v2.73.0/workflows/pipelines/sagemaker.workflow.pipelines.html#sagemaker.workflow.check_job_config.CheckJobConfig) class, and we can use the `DataQualityCheckConfig` class to configure the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0b80bcab-d2c5-437c-a1c8-8eea208c0e29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "data_quality_baseline_step = QualityCheckStep(\n",
    "    name=\"generate-data-quality-baseline\",\n",
    "    \n",
    "    check_job_config = CheckJobConfig(\n",
    "        instance_type=\"ml.t3.xlarge\",\n",
    "        instance_count=1,\n",
    "        volume_size_in_gb=20,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    "    ),\n",
    "    \n",
    "    quality_check_config = DataQualityCheckConfig(\n",
    "        # We will use the train dataset we generated during the preprocessing \n",
    "        # step to generate the data quality baseline.\n",
    "        baseline_dataset=preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\"train-baseline\"].S3Output.S3Uri,\n",
    "\n",
    "        dataset_format=DatasetFormat.json(lines=True),\n",
    "        output_s3_uri=DATA_QUALITY_LOCATION\n",
    "    ),\n",
    "    \n",
    "    skip_check=True,\n",
    "    register_new_baseline=True,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917fe920-172d-4b07-bd7d-b2ecea536319",
   "metadata": {},
   "source": [
    "# Session 6 - Model Monitoring\n",
    "\n",
    "This session aims to set up a monitoring process to analyze the quality of the model predictions. For this, we need to generate ground truth for the data captured by the endpoint and compare it with a baseline performance.\n",
    "\n",
    "Check [Amazon SageMaker Model Monitor](https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_model_monitoring.html) for a brief explanation of how to use SageMaker's Model Monitoring functionality. [Monitor models for data and model quality, bias, and explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) is a much more extensive guide to Model Monitoring in Amazon SageMaker.\n",
    "\n",
    "Here is what the Pipeline will look like at the end of this session:\n",
    "\n",
    "<img src='images/session6-pipeline.png' alt='Session 6 Pipeline' width=\"600\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "748c47c5-71e6-4f76-9a8b-9a5f4716e806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.quality_check_step import ModelQualityCheckConfig\n",
    "\n",
    "from sagemaker.inputs import CreateModelInput, TransformInput\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.workflow.steps import CreateModelStep, TransformStep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81430dfd-2524-43e4-bfe9-c6545316005d",
   "metadata": {},
   "source": [
    "## Step 1 - Creating Test Predictions\n",
    "\n",
    "To create a baseline to compare the model performance, we must create predictions for the test set and compare them with the predictions from the model. We can do this by running a Batch Transform Job to predict every sample from the test dataset. We can use a [Transform Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-transform) as part of the pipeline to run this job. You can check [Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) for more information about Batch Transform Jobs.\n",
    "\n",
    "The Transform Step requires a model to generate predictions, so we need a Model Step that creates a model.\n",
    "\n",
    "We also need to configure the [Batch Transform Job](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) using a [Transform Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-transform). This Batch Transform Job will run every sample from the training dataset through the model so we can compute the baseline metrics. We can use an instance of the [Transformer](https://sagemaker.readthedocs.io/en/stable/api/inference/transformer.html) class to configure the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1987a788-de7a-4f60-ac8d-819d9ffcdf8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_model_step = ModelStep(\n",
    "    name=\"create\",\n",
    "    display_name=\"create-model\",\n",
    "    step_args=repacked_model.create(\n",
    "        instance_type=\"ml.m5.large\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=create_model_step.properties.ModelName,\n",
    "    base_transform_job_name=\"transform\",\n",
    "\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    \n",
    "    accept=\"application/json\",\n",
    "    strategy=\"SingleRecord\",\n",
    "    assemble_with=\"Line\",\n",
    "    \n",
    "    output_path=f\"{S3_LOCATION}/transform\",\n",
    ")\n",
    "\n",
    "# Workaround for bug in SDK version 2.171.0\n",
    "# https://github.com/aws/sagemaker-python-sdk/issues/3991\n",
    "transformer._current_job_name = \"transform\"\n",
    "\n",
    "generate_test_predictions_step = TransformStep(\n",
    "    name=\"generate-test-predictions\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(\n",
    "        \n",
    "        # We will use the test dataset we generated during the preprocessing \n",
    "        # step to run it through the model and generate predictions.\n",
    "        data=preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\"test-baseline\"].S3Output.S3Uri,\n",
    "\n",
    "        join_source=\"Input\",\n",
    "        content_type=\"application/json\",\n",
    "        split_type=\"Line\",\n",
    "    ),\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fafc7c4-6fef-4832-8b99-8c45d078fdd2",
   "metadata": {},
   "source": [
    "## Step 2 - Generating a Baseline\n",
    "\n",
    "Let's now configure the [Quality Check Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-quality-check) and feed it the data we generated in the Transform Step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9aa3a284-8763-4000-a263-70314b530652",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "model_quality_location = f\"{S3_LOCATION}/monitoring/model-quality\"\n",
    "\n",
    "model_quality_baseline_step = QualityCheckStep(\n",
    "    name=\"generate-model-quality-baseline\",\n",
    "    \n",
    "    check_job_config = CheckJobConfig(\n",
    "        instance_type=\"ml.t3.xlarge\",\n",
    "        instance_count=1,\n",
    "        volume_size_in_gb=20,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    "    ),\n",
    "    \n",
    "    quality_check_config = ModelQualityCheckConfig(\n",
    "        # We are going to use the output of the Transform Step to generate\n",
    "        # the model quality baseline.\n",
    "        baseline_dataset=generate_test_predictions_step.properties.TransformOutput.S3OutputPath,\n",
    "\n",
    "        dataset_format=DatasetFormat.json(lines=True),\n",
    "\n",
    "        # We need to specify the problem type and the fields where the prediction\n",
    "        # and groundtruth are so the process knows how to interpret the results.\n",
    "        problem_type=\"MulticlassClassification\",\n",
    "        inference_attribute=\"$.SageMakerOutput.species\",\n",
    "        ground_truth_attribute=\"species\",\n",
    "\n",
    "        output_s3_uri=model_quality_location,\n",
    "    ),\n",
    "    \n",
    "    skip_check=True,\n",
    "    register_new_baseline=True,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693535ba-fca7-4e89-a4cb-b4f333fa2d03",
   "metadata": {},
   "source": [
    "## Step 3 - Setting up Model Metrics\n",
    "\n",
    "We can configure a new set of [ModelMetrics](https://sagemaker.readthedocs.io/en/stable/api/inference/model_monitor.html#sagemaker.model_metrics.ModelMetrics) using the results of the Data and Model Quality Steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a773f134-ac2f-4dba-976e-9b7f0b384b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    \n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "drift_check_baselines = DriftCheckBaselines(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3487a0-05ad-4f3a-8f50-9884dc2aef64",
   "metadata": {},
   "source": [
    "## Step 4 - Registering the Model\n",
    "\n",
    "We need to redefine the Model Step to register the [TensorFlowModel](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-serving-model) so it takes into account the new metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00b5e6-9858-4acc-bbfe-a2ce24ec20e0",
   "metadata": {},
   "source": [
    "## Step 5 - Setting up the Condition Step\n",
    "\n",
    "We only want to compute the model quality baseline if the model's performance is above the predefined threshold. The [Condition Step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition) will gate all necessary steps to compute the baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "50a79c24-2c0b-400f-b52c-f46d39218b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We'll send this payload to the endpoint. Notice how each line contains\n",
    "# the information of a penguin. The endpoint will return the predictions\n",
    "# for each of these lines.\n",
    "# payload = \"\"\"\n",
    "# 0.6569590202313976, -1.0813829646495108, 1.2097102831892812, 0.9226343641317372, 1.0, 0.0, 0.0\n",
    "# -0.7751048801481084, 0.8822689351285553,  -1.2168066120762704, 0.9226343641317372, 0.0, 1.0, 0.0\n",
    "# -0.837387834894918, 0.3386660813829646, -0.26237731892812, -1.92351941317372, 0.0, 0.0, 1.0\n",
    "# \"\"\"\n",
    "\n",
    "# # We can now send the request to the endpoint and process the response.\n",
    "# predictor = Predictor(endpoint_name=ENDPOINT)\n",
    "# response = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "# response = json.loads(response.decode(\"utf-8\"))\n",
    "\n",
    "# print(json.dumps(response, indent=2))\n",
    "# print(f\"\\nSpecies: {np.argmax(response['predictions'], axis=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bacaa9c6-22b0-48df-b138-95b6422fe834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[gte_approved],\n",
    "    if_steps=[\n",
    "        create_model_step, \n",
    "        generate_test_predictions_step,\n",
    "        model_quality_baseline_step,\n",
    "        register_model_step,\n",
    "        deploy_step\n",
    "    ],\n",
    "    else_steps=[fail_step_min], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a7905-2550-4979-b885-f2daabb5d45e",
   "metadata": {},
   "source": [
    "## Step 6 - Setting up the Pipeline\n",
    "\n",
    "We can now define the SageMaker Pipeline and submit its definition to the SageMaker Pipelines service to create the pipeline if it doesn't exist or update it if it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4da5e453-acd8-47a0-a39f-264d05dd93d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "Using provided s3_resource\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "Using provided s3_resource\n",
      "Using provided s3_resource\n",
      "Endpoint does not exist\n"
     ]
    }
   ],
   "source": [
    "session6_pipeline = Pipeline(\n",
    "    name=\"final-penguins-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        data_capture_percentage,\n",
    "        data_capture_destination,\n",
    "        accuracy_threshold,\n",
    "        min_accuracy_threshold,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_data_step,\n",
    "        data_quality_baseline_step,\n",
    "        tune_model_step,\n",
    "        eval_model_step,\n",
    "        condition_step,         \n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config\n",
    ")\n",
    "\n",
    "session6_pipeline.upsert(role_arn=role)\n",
    "try:\n",
    "    response = boto3.client(\"sagemaker\").delete_endpoint(\n",
    "        EndpointName=\"penguins-endpoint\",\n",
    "    )\n",
    "except:\n",
    "    print(\"Endpoint does not exist\")\n",
    "    \n",
    "# session6_pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "01d0caaa-ffc8-49a9-a650-222cab325d08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://eu-north-1.console.aws.amazon.com/cloudwatch/home?region=eu-north-1#logEventViewer:group=/aws/sagemaker/Endpoints/penguins-endpoint in account 253909639528 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-30f284943498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0minference_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minference_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/base_predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id, custom_attributes)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcustom_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         )\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 )\n\u001b[1;32m    534\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://eu-north-1.console.aws.amazon.com/cloudwatch/home?region=eu-north-1#logEventViewer:group=/aws/sagemaker/Endpoints/penguins-endpoint in account 253909639528 for more information."
     ]
    }
   ],
   "source": [
    "\n",
    "endpoint = 'penguins-endpoint'\n",
    "\n",
    "# Read image into memory\n",
    "payload=[{\n",
    "        \"island\": \"Biscoe\",\n",
    "        \"culmen_length_mm\": 48.6,\n",
    "        \"culmen_depth_mm\": 16.0,\n",
    "        \"flipper_length_mm\": 230.0,\n",
    "        \"body_mass_g\": 5800.0,\n",
    "    },{\n",
    "        \"island\": \"Dream\",\n",
    "        \"culmen_length_mm\": 43.2,\n",
    "        \"culmen_depth_mm\": 17.5,\n",
    "        \"flipper_length_mm\": 175.0,\n",
    "        \"body_mass_g\": 3500.0,\n",
    "    },{\n",
    "        \"island\": \"Torgersen\",\n",
    "        \"culmen_length_mm\": 38.6,\n",
    "        \"culmen_depth_mm\": 16.0,\n",
    "        \"flipper_length_mm\": 176.0,\n",
    "        \"body_mass_g\": 3700.0,\n",
    "    }]\n",
    "\n",
    "predictor = Predictor(endpoint)\n",
    "inference_response = predictor.predict(data=json.dumps(payload))\n",
    "print (inference_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7efe9-a85c-4dad-81ec-bcde0b034e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train my estimator\n",
    "pytorch_estimator = PyTorch(entry_point=f'{CODE_FOLDER}/{ENDPOINT_CODE_FOLDER}/inference.py',\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            instance_count=1,\n",
    "                            framework_version='1.8.0',\n",
    "                            py_version='py3')\n",
    "pytorch_estimator.fit('s3://my_bucket/my_training_data/')\n",
    "\n",
    "# Deploy my estimator to a SageMaker Endpoint and get a Predictor\n",
    "predictor = pytorch_estimator.deploy(instance_type='ml.m4.xlarge',\n",
    "                                     initial_instance_count=1)\n",
    "\n",
    "# `data` is a NumPy array or a Python list.\n",
    "# `response` is a NumPy array.\n",
    "response = predictor.predict(data)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-north-1:243637512696:image/pytorch-1.10-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
