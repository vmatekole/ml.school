{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c712cfc-5ac2-481f-8019-815e97bfeca2",
   "metadata": {},
   "source": [
    "**Note:** Make sure you go through the [Setup Notebook](penguins-setup.ipynb) notebook once at the start of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de2fcd6-69c7-461d-bd80-771db1ba5fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mName: sagemaker\n",
      "Version: 2.173.0\n",
      "Summary: Open source library for training and deploying models on Amazon SageMaker.\n",
      "Home-page: https://github.com/aws/sagemaker-python-sdk/\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: /opt/conda/lib/python3.8/site-packages\n",
      "Requires: attrs, boto3, cloudpickle, google-pasta, importlib-metadata, jsonschema, numpy, packaging, pandas, pathos, platformdirs, protobuf, PyYAML, schema, smdebug-rulesconfig, tblib\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# !pip install -q --upgrade pip\n",
    "# !pip install -q --upgrade awscli boto3\n",
    "!pip install -q --upgrade scikit-learn==0.23.2\n",
    "# !pip install -q --upgrade PyYAML==6.0\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q --upgrade awscli boto3\n",
    "!pip install -q --upgrade sagemaker==2.173.0\n",
    "!pip install -q --upgrade sagemaker_inference\n",
    "!pip show sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91a5f8ec-113a-4f91-8f66-eab31d934bab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "CODE_FOLDER = Path(\"code\")\n",
    "CODE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sys.path.append(f\"./{CODE_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "915b1d0b-d9da-4529-aca5-fd1c08a36f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import tarfile\n",
    "import tempfile\n",
    "import time\n",
    "from datetime import datetime\n",
    "from threading import Event, Thread\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "from constants import *\n",
    "from endpoint.inference import *\n",
    "from evaluation import evaluate\n",
    "from IPython.display import JSON\n",
    "from preprocessor import preprocess\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "from sagemaker.inputs import (CreateModelInput, FileSystemInput, TrainingInput,\n",
    "                              TransformInput)\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.model_monitor import (CronExpressionGenerator,\n",
    "                                     DefaultModelMonitor, EndpointInput,\n",
    "                                     ModelQualityMonitor, MonitoringExecution)\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.parameter import ContinuousParameter, IntegerParameter\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.pytorch import PyTorch, PyTorchProcessor\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import (ConditionGreaterThanOrEqualTo,\n",
    "                                           ConditionLessThanOrEqualTo)\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.functions import Join, JsonGet\n",
    "from sagemaker.workflow.lambda_step import (LambdaOutput, LambdaOutputTypeEnum,\n",
    "                                            LambdaStep)\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.parameters import (ParameterBoolean, ParameterFloat,\n",
    "                                           ParameterInteger, ParameterString)\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.pipeline_definition_config import \\\n",
    "    PipelineDefinitionConfig\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.quality_check_step import (DataQualityCheckConfig,\n",
    "                                                   ModelQualityCheckConfig,\n",
    "                                                   QualityCheckStep)\n",
    "from sagemaker.workflow.steps import (CacheConfig, CreateModelStep,\n",
    "                                      ProcessingStep, TrainingStep,\n",
    "                                      TransformStep, TuningStep)\n",
    "\n",
    "\n",
    "\n",
    "from nn import train\n",
    "\n",
    "MODEL_PACKAGE_GROUP = \"penguins\"\n",
    "ENDPOINT = \"penguins-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f122a4-acff-4687-91b9-bfef13567d88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders: ['train-baseline', 'test-baseline', 'train', 'validation', 'test', 'pipeline', 'classes']\n"
     ]
    }
   ],
   "source": [
    "# Test preprocessing script\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    preprocess(\n",
    "        base_directory=directory, \n",
    "        data_filepath=DATA_FILEPATH\n",
    "    )\n",
    "    \n",
    "    print(f\"Folders: {os.listdir(directory)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86de7edd-18b0-40d1-ac8e-0f3ef4469be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preprocess_data_step parameters\n",
    "dataset_location = ParameterString(\n",
    "    name=\"dataset_location\",\n",
    "    default_value=f\"{S3_LOCATION}/data.csv\",\n",
    ")\n",
    "\n",
    "preprocessor_destination = ParameterString(\n",
    "    name=\"preprocessor_destination\",\n",
    "    default_value=f\"{S3_LOCATION}/preprocessing\",\n",
    ")\n",
    "\n",
    "pipeline_definition_config = PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    "\n",
    "cache_config = CacheConfig(\n",
    "    enable_caching=True, \n",
    "    expire_after=\"15d\"\n",
    ")\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    base_job_name=\"penguins-preprocessing\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2187b65e-e504-40a5-ad05-82f54885805c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define preprocessing step\n",
    "preprocess_data_step = ProcessingStep(\n",
    "    name=\"preprocess-data\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=dataset_location, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "        ProcessingOutput(output_name=\"pipeline\", source=\"/opt/ml/processing/pipeline\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"classes\", source=\"/opt/ml/processing/classes\", destination=preprocessor_destination),\n",
    "        ProcessingOutput(output_name=\"train-baseline\", source=\"/opt/ml/processing/train-baseline\"),\n",
    "        ProcessingOutput(output_name=\"test-baseline\", source=\"/opt/ml/processing/test-baseline\"),\n",
    "    ],\n",
    "    code=f\"{CODE_FOLDER}/preprocessor.py\",\n",
    "    cache_config=cache_config\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7df253-77bf-44c2-9230-b41dbe28cc0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Undesirable but this is a workaround a bug related to importing code libraries for the endpoint pipeline\n",
    "!cp {CODE_FOLDER}/nn.py  {CODE_FOLDER}/endpoint/nn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14ea27ce-c453-4cb0-b309-dbecd732957e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] - loss: 1.1082, val_accuracy: 0.2050\n",
      "Epoch [2/100] - loss: 1.1070, val_accuracy: 0.2134\n",
      "Epoch [3/100] - loss: 1.1058, val_accuracy: 0.2176\n",
      "Epoch [4/100] - loss: 1.1046, val_accuracy: 0.2092\n",
      "Epoch [5/100] - loss: 1.1034, val_accuracy: 0.2134\n",
      "Epoch [6/100] - loss: 1.1022, val_accuracy: 0.2218\n",
      "Epoch [7/100] - loss: 1.1009, val_accuracy: 0.2259\n",
      "Epoch [8/100] - loss: 1.0997, val_accuracy: 0.2385\n",
      "Epoch [9/100] - loss: 1.0985, val_accuracy: 0.2594\n",
      "Epoch [10/100] - loss: 1.0973, val_accuracy: 0.2594\n",
      "Epoch [11/100] - loss: 1.0961, val_accuracy: 0.2636\n",
      "Epoch [12/100] - loss: 1.0948, val_accuracy: 0.2762\n",
      "Epoch [13/100] - loss: 1.0936, val_accuracy: 0.2720\n",
      "Epoch [14/100] - loss: 1.0923, val_accuracy: 0.3013\n",
      "Epoch [15/100] - loss: 1.0911, val_accuracy: 0.3264\n",
      "Epoch [16/100] - loss: 1.0898, val_accuracy: 0.3891\n",
      "Epoch [17/100] - loss: 1.0885, val_accuracy: 0.4561\n",
      "Epoch [18/100] - loss: 1.0873, val_accuracy: 0.5732\n",
      "Epoch [19/100] - loss: 1.0860, val_accuracy: 0.6820\n",
      "Epoch [20/100] - loss: 1.0846, val_accuracy: 0.7197\n",
      "Epoch [21/100] - loss: 1.0833, val_accuracy: 0.7197\n",
      "Epoch [22/100] - loss: 1.0819, val_accuracy: 0.7197\n",
      "Epoch [23/100] - loss: 1.0806, val_accuracy: 0.7238\n",
      "Epoch [24/100] - loss: 1.0791, val_accuracy: 0.7280\n",
      "Epoch [25/100] - loss: 1.0777, val_accuracy: 0.7322\n",
      "Epoch [26/100] - loss: 1.0762, val_accuracy: 0.7364\n",
      "Epoch [27/100] - loss: 1.0747, val_accuracy: 0.7406\n",
      "Epoch [28/100] - loss: 1.0732, val_accuracy: 0.7406\n",
      "Epoch [29/100] - loss: 1.0716, val_accuracy: 0.7364\n",
      "Epoch [30/100] - loss: 1.0700, val_accuracy: 0.7364\n",
      "Epoch [31/100] - loss: 1.0684, val_accuracy: 0.7364\n",
      "Epoch [32/100] - loss: 1.0667, val_accuracy: 0.7322\n",
      "Epoch [33/100] - loss: 1.0649, val_accuracy: 0.7322\n",
      "Epoch [34/100] - loss: 1.0632, val_accuracy: 0.7322\n",
      "Epoch [35/100] - loss: 1.0613, val_accuracy: 0.7322\n",
      "Epoch [36/100] - loss: 1.0594, val_accuracy: 0.7322\n",
      "Epoch [37/100] - loss: 1.0575, val_accuracy: 0.7322\n",
      "Epoch [38/100] - loss: 1.0554, val_accuracy: 0.7322\n",
      "Epoch [39/100] - loss: 1.0534, val_accuracy: 0.7322\n",
      "Epoch [40/100] - loss: 1.0512, val_accuracy: 0.7322\n",
      "Epoch [41/100] - loss: 1.0490, val_accuracy: 0.7322\n",
      "Epoch [42/100] - loss: 1.0467, val_accuracy: 0.7322\n",
      "Epoch [43/100] - loss: 1.0443, val_accuracy: 0.7364\n",
      "Epoch [44/100] - loss: 1.0419, val_accuracy: 0.7364\n",
      "Epoch [45/100] - loss: 1.0394, val_accuracy: 0.7280\n",
      "Epoch [46/100] - loss: 1.0368, val_accuracy: 0.7238\n",
      "Epoch [47/100] - loss: 1.0341, val_accuracy: 0.7238\n",
      "Epoch [48/100] - loss: 1.0313, val_accuracy: 0.7280\n",
      "Epoch [49/100] - loss: 1.0284, val_accuracy: 0.7280\n",
      "Epoch [50/100] - loss: 1.0255, val_accuracy: 0.7322\n",
      "Epoch [51/100] - loss: 1.0224, val_accuracy: 0.7322\n",
      "Epoch [52/100] - loss: 1.0193, val_accuracy: 0.7280\n",
      "Epoch [53/100] - loss: 1.0160, val_accuracy: 0.7280\n",
      "Epoch [54/100] - loss: 1.0127, val_accuracy: 0.7322\n",
      "Epoch [55/100] - loss: 1.0093, val_accuracy: 0.7280\n",
      "Epoch [56/100] - loss: 1.0058, val_accuracy: 0.7280\n",
      "Epoch [57/100] - loss: 1.0022, val_accuracy: 0.7280\n",
      "Epoch [58/100] - loss: 0.9986, val_accuracy: 0.7280\n",
      "Epoch [59/100] - loss: 0.9949, val_accuracy: 0.7280\n",
      "Epoch [60/100] - loss: 0.9911, val_accuracy: 0.7280\n",
      "Epoch [61/100] - loss: 0.9874, val_accuracy: 0.7280\n",
      "Epoch [62/100] - loss: 0.9835, val_accuracy: 0.7238\n",
      "Epoch [63/100] - loss: 0.9797, val_accuracy: 0.7238\n",
      "Epoch [64/100] - loss: 0.9759, val_accuracy: 0.7238\n",
      "Epoch [65/100] - loss: 0.9720, val_accuracy: 0.7322\n",
      "Epoch [66/100] - loss: 0.9682, val_accuracy: 0.7322\n",
      "Epoch [67/100] - loss: 0.9644, val_accuracy: 0.7364\n",
      "Epoch [68/100] - loss: 0.9606, val_accuracy: 0.7364\n",
      "Epoch [69/100] - loss: 0.9569, val_accuracy: 0.7406\n",
      "Epoch [70/100] - loss: 0.9532, val_accuracy: 0.7406\n",
      "Epoch [71/100] - loss: 0.9496, val_accuracy: 0.7406\n",
      "Epoch [72/100] - loss: 0.9461, val_accuracy: 0.7406\n",
      "Epoch [73/100] - loss: 0.9426, val_accuracy: 0.7406\n",
      "Epoch [74/100] - loss: 0.9392, val_accuracy: 0.7490\n",
      "Epoch [75/100] - loss: 0.9359, val_accuracy: 0.7490\n",
      "Epoch [76/100] - loss: 0.9327, val_accuracy: 0.7531\n",
      "Epoch [77/100] - loss: 0.9296, val_accuracy: 0.7531\n",
      "Epoch [78/100] - loss: 0.9266, val_accuracy: 0.7531\n",
      "Epoch [79/100] - loss: 0.9236, val_accuracy: 0.7615\n",
      "Epoch [80/100] - loss: 0.9208, val_accuracy: 0.7615\n",
      "Epoch [81/100] - loss: 0.9180, val_accuracy: 0.7615\n",
      "Epoch [82/100] - loss: 0.9154, val_accuracy: 0.7657\n",
      "Epoch [83/100] - loss: 0.9128, val_accuracy: 0.7657\n",
      "Epoch [84/100] - loss: 0.9103, val_accuracy: 0.7699\n",
      "Epoch [85/100] - loss: 0.9078, val_accuracy: 0.7741\n",
      "Epoch [86/100] - loss: 0.9055, val_accuracy: 0.7741\n",
      "Epoch [87/100] - loss: 0.9032, val_accuracy: 0.7741\n",
      "Epoch [88/100] - loss: 0.9010, val_accuracy: 0.7741\n",
      "Epoch [89/100] - loss: 0.8989, val_accuracy: 0.7741\n",
      "Epoch [90/100] - loss: 0.8968, val_accuracy: 0.7741\n",
      "Epoch [91/100] - loss: 0.8949, val_accuracy: 0.7741\n",
      "Epoch [92/100] - loss: 0.8929, val_accuracy: 0.7741\n",
      "Epoch [93/100] - loss: 0.8911, val_accuracy: 0.7741\n",
      "Epoch [94/100] - loss: 0.8892, val_accuracy: 0.7741\n",
      "Epoch [95/100] - loss: 0.8875, val_accuracy: 0.7741\n",
      "Epoch [96/100] - loss: 0.8857, val_accuracy: 0.7741\n",
      "Epoch [97/100] - loss: 0.8841, val_accuracy: 0.7741\n",
      "Epoch [98/100] - loss: 0.8825, val_accuracy: 0.7741\n",
      "Epoch [99/100] - loss: 0.8809, val_accuracy: 0.7741\n",
      "Epoch [100/100] - loss: 0.8793, val_accuracy: 0.7782\n",
      "Model saved: /tmp/tmprms8bk_4/model/001/model.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a temporary directory to test the training.\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    # First, we preprocess the data and create the \n",
    "    # dataset splits.\n",
    "    preprocess(\n",
    "        base_directory=directory, \n",
    "        data_filepath=DATA_FILEPATH\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        base_directory=directory, \n",
    "        train_path=Path(directory) / \"train\", \n",
    "        validation_path=Path(directory) / \"validation\",\n",
    "        epochs=100,\n",
    "        learning_rate=0.01\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "038ff2e5-ed28-445b-bc03-4e996ec2286f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define tuning step\n",
    "objective_metric_name = \"val_accuracy\"\n",
    "objective_type = \"Maximize\"\n",
    "metric_definitions = [{\"Name\": objective_metric_name, \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"}]\n",
    "    \n",
    "hyperparameter_ranges = {\n",
    "    \"epochs\": IntegerParameter(10, 100),\n",
    "    \"batch_size\": IntegerParameter(8, 16),\n",
    "    \"learning_rate\": ContinuousParameter(0.007, 0.01),\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=f\"{CODE_FOLDER}/nn.py\",\n",
    "    framework_version=\"1.8\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    py_version=\"py36\",\n",
    "    instance_count=1,\n",
    "    script_mode=True,\n",
    "    \n",
    "    # The default profiler rule includes a timestamp which will change each time\n",
    "    # the pipeline is upserted, causing cache misses. Since we don't need\n",
    "    # profiling, we can disable it to take advantage of caching.\n",
    "    disable_profiler=True,\n",
    "\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    objective_type=objective_type,\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf5dd9a7-8643-4fbb-8eb4-40f39011e27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tune_model_step = TuningStep(\n",
    "    name = \"tune-model\",\n",
    "    tuner=tuner,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a2540d8-278a-4953-bc54-0469d154427d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - loss: 1.1271, val_accuracy: 0.2092\n",
      "Epoch [2/50] - loss: 1.1262, val_accuracy: 0.2092\n",
      "Epoch [3/50] - loss: 1.1253, val_accuracy: 0.2092\n",
      "Epoch [4/50] - loss: 1.1244, val_accuracy: 0.2092\n",
      "Epoch [5/50] - loss: 1.1235, val_accuracy: 0.2092\n",
      "Epoch [6/50] - loss: 1.1227, val_accuracy: 0.2092\n",
      "Epoch [7/50] - loss: 1.1218, val_accuracy: 0.2092\n",
      "Epoch [8/50] - loss: 1.1210, val_accuracy: 0.2092\n",
      "Epoch [9/50] - loss: 1.1202, val_accuracy: 0.2092\n",
      "Epoch [10/50] - loss: 1.1194, val_accuracy: 0.2092\n",
      "Epoch [11/50] - loss: 1.1187, val_accuracy: 0.2092\n",
      "Epoch [12/50] - loss: 1.1179, val_accuracy: 0.2092\n",
      "Epoch [13/50] - loss: 1.1172, val_accuracy: 0.2092\n",
      "Epoch [14/50] - loss: 1.1165, val_accuracy: 0.2092\n",
      "Epoch [15/50] - loss: 1.1158, val_accuracy: 0.2092\n",
      "Epoch [16/50] - loss: 1.1151, val_accuracy: 0.2092\n",
      "Epoch [17/50] - loss: 1.1144, val_accuracy: 0.2092\n",
      "Epoch [18/50] - loss: 1.1137, val_accuracy: 0.2092\n",
      "Epoch [19/50] - loss: 1.1131, val_accuracy: 0.2092\n",
      "Epoch [20/50] - loss: 1.1124, val_accuracy: 0.2092\n",
      "Epoch [21/50] - loss: 1.1118, val_accuracy: 0.2092\n",
      "Epoch [22/50] - loss: 1.1112, val_accuracy: 0.2050\n",
      "Epoch [23/50] - loss: 1.1106, val_accuracy: 0.2008\n",
      "Epoch [24/50] - loss: 1.1100, val_accuracy: 0.2008\n",
      "Epoch [25/50] - loss: 1.1094, val_accuracy: 0.1883\n",
      "Epoch [26/50] - loss: 1.1088, val_accuracy: 0.1841\n",
      "Epoch [27/50] - loss: 1.1082, val_accuracy: 0.1674\n",
      "Epoch [28/50] - loss: 1.1076, val_accuracy: 0.1464\n",
      "Epoch [29/50] - loss: 1.1070, val_accuracy: 0.1506\n",
      "Epoch [30/50] - loss: 1.1065, val_accuracy: 0.1799\n",
      "Epoch [31/50] - loss: 1.1059, val_accuracy: 0.2176\n",
      "Epoch [32/50] - loss: 1.1054, val_accuracy: 0.2301\n",
      "Epoch [33/50] - loss: 1.1048, val_accuracy: 0.2385\n",
      "Epoch [34/50] - loss: 1.1043, val_accuracy: 0.2552\n",
      "Epoch [35/50] - loss: 1.1038, val_accuracy: 0.2720\n",
      "Epoch [36/50] - loss: 1.1033, val_accuracy: 0.3013\n",
      "Epoch [37/50] - loss: 1.1027, val_accuracy: 0.3347\n",
      "Epoch [38/50] - loss: 1.1022, val_accuracy: 0.3431\n",
      "Epoch [39/50] - loss: 1.1017, val_accuracy: 0.3515\n",
      "Epoch [40/50] - loss: 1.1012, val_accuracy: 0.3556\n",
      "Epoch [41/50] - loss: 1.1007, val_accuracy: 0.3640\n",
      "Epoch [42/50] - loss: 1.1002, val_accuracy: 0.3682\n",
      "Epoch [43/50] - loss: 1.0997, val_accuracy: 0.3682\n",
      "Epoch [44/50] - loss: 1.0992, val_accuracy: 0.3682\n",
      "Epoch [45/50] - loss: 1.0988, val_accuracy: 0.3682\n",
      "Epoch [46/50] - loss: 1.0983, val_accuracy: 0.3682\n",
      "Epoch [47/50] - loss: 1.0978, val_accuracy: 0.3724\n",
      "Epoch [48/50] - loss: 1.0974, val_accuracy: 0.3766\n",
      "Epoch [49/50] - loss: 1.0969, val_accuracy: 0.3849\n",
      "Epoch [50/50] - loss: 1.0964, val_accuracy: 0.3849\n",
      "Model saved: /tmp/tmpgw55e9xx/model/001/model.pth\n",
      "{'metrics': {'accuracy': {'value': 0.39215686274509803}, 'Precision': {'value': 0.6121568627450981}, 'Recall': {'value': 0.39215686274509803}, 'F1': {'value': 0.24281898266552998}, 'num_samples': {'value': 51}}}\n",
      "{'metrics': {'accuracy': {'value': 0.39215686274509803}, 'Precision': {'value': 0.6121568627450981}, 'Recall': {'value': 0.39215686274509803}, 'F1': {'value': 0.24281898266552998}, 'num_samples': {'value': 51}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    preprocess(\n",
    "        base_directory=directory, \n",
    "        data_filepath=DATA_FILEPATH\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        base_directory=directory, \n",
    "        train_path=Path(directory) / \"train\", \n",
    "        validation_path=Path(directory) / \"validation\",\n",
    "        epochs=50\n",
    "    )\n",
    "    \n",
    "    # After training a model, we need to prepare a package just like\n",
    "    # SageMaker would. This package is what the evaluation script is\n",
    "    # expecting as an input.\n",
    "    with tarfile.open(Path(directory) / \"model.tar.gz\", \"w:gz\") as tar:\n",
    "        tar.add(Path(directory) / \"model\" / \"001\", arcname=\"001\")\n",
    "        \n",
    "    \n",
    "    # We can now call the evaluation script.\n",
    "    evaluate(\n",
    "        model_path=directory, \n",
    "        test_path=Path(directory) / \"test\",\n",
    "        output_path=Path(directory) / \"evaluation\",\n",
    "        evaluation_name=\"evaluation\",\n",
    "    )\n",
    "    \n",
    "    with open(Path(directory) / \"evaluation\" / f\"evaluation.json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48139a07-5c8e-4bc6-b666-bf9531f7f520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    }
   ],
   "source": [
    "pytorch_processor = PyTorchProcessor(\n",
    "    base_job_name=\"penguins-evaluation-processor\",\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=PipelineSession(),\n",
    ")\n",
    "\n",
    "# This is a workaround to a problem with the SageMaker SDK: \n",
    "# By default, the TensorFlowProcessor runs the script using\n",
    "# /bin/bash as its entrypoint. We want to ensure we run it \n",
    "# using python3.\n",
    "pytorch_processor.framework_entrypoint_command = [\"python3\"]\n",
    "\n",
    "eval_winner_name = \"evaluate-winner-model\"\n",
    "\n",
    "# We want to map the evaluation report that we generate inside\n",
    "# the evaluation script so we can later reference it.\n",
    "def create_eval_report(report_name):\n",
    "    return PropertyFile(\n",
    "        name=report_name,\n",
    "        output_name=\"evaluation\",\n",
    "        path=f\"{report_name}.json\",\n",
    "    )\n",
    "\n",
    "def create_eval_process_step(evaluation_name, report, top_k=0):\n",
    "    return ProcessingStep(\n",
    "        name=evaluation_name,\n",
    "        processor=pytorch_processor,\n",
    "        inputs=[\n",
    "            ProcessingInput(source=preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\"\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=(\n",
    "                    tune_model_step.get_top_model_s3_uri(top_k=top_k, s3_bucket=sagemaker_session.default_bucket()) \n",
    "                ),\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\", destination=f\"{S3_LOCATION}/evaluation\"),\n",
    "        ],\n",
    "        code=f'{CODE_FOLDER}/evaluation.py',\n",
    "        job_arguments=[\"--evaluation_name\", evaluation_name],\n",
    "        property_files=[report],\n",
    "        cache_config=cache_config,\n",
    "    )\n",
    "    \n",
    "eval_winner_report = create_eval_report(eval_winner_name)\n",
    "\n",
    "eval_model_step = create_eval_process_step(eval_winner_name, \n",
    "                                        eval_winner_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4982146f-0c0f-4938-b5d0-06db45a58531",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(on=\"/\", values=[\n",
    "            eval_model_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output']['S3Uri'], f\"{eval_winner_name}.json\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "model_package_group_name = \"penguins\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52a48cef-fb78-412b-a5c6-977eafe98e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py:297: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def get_model(top_k=0):\n",
    "    return PyTorchModel(\n",
    "        model_data=(\n",
    "            tune_model_step.get_top_model_s3_uri(top_k, s3_bucket=PipelineSession().default_bucket())\n",
    "        ),\n",
    "        framework_version=\"1.8\",\n",
    "        py_version=\"py36\",\n",
    "        sagemaker_session=PipelineSession(),\n",
    "        role=role,\n",
    "    )\n",
    "\n",
    "def model_registry_args(model,\n",
    "                        model_metrics, \n",
    "                        approval_status=\"PendingManualApproval\"):\n",
    "    return model.register(\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        model_metrics=model_metrics,\n",
    "        approval_status=approval_status,\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"text/csv\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        transform_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"PYTORCH\",\n",
    "        framework_version=\"1.8\",\n",
    "    )\n",
    "\n",
    "model = get_model() \n",
    "\n",
    "args_approved = model_registry_args(model, \n",
    "                                    model_metrics, \n",
    "                                    \"Approved\")\n",
    "\n",
    "args_pending = model_registry_args(model,\n",
    "                                model_metrics)\n",
    "\n",
    "register_step_approved = ModelStep(\n",
    "    name=\"register-model-approved\",\n",
    "    step_args=args_approved,\n",
    ")\n",
    "\n",
    "register_step_pending = ModelStep(\n",
    "    name=\"register-model-pending-approval\",\n",
    "    step_args=args_pending,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36e2a2b1-6711-4266-95d8-d2aebd52e199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_threshold = ParameterFloat(\n",
    "    name=\"accuracy_threshold\", \n",
    "    default_value=0.70\n",
    ")\n",
    "\n",
    "min_accuracy_threshold = ParameterFloat(\n",
    "    name=\"accuracy_threshold_min\", \n",
    "    default_value=0.50\n",
    ")\n",
    "\n",
    "def gte_eval_condition(step, report, accuracy):\n",
    "    return ConditionGreaterThanOrEqualTo(\n",
    "        left=JsonGet(\n",
    "            step_name=step.name,\n",
    "            property_file=report,\n",
    "            json_path=\"metrics.accuracy.value\"\n",
    "        ),\n",
    "        right=accuracy\n",
    "    )\n",
    "\n",
    "def lte_eval_condition(step, report, accuracy):\n",
    "    return ConditionLessThanOrEqualTo(\n",
    "        left=JsonGet(\n",
    "            step_name=step.name,\n",
    "            property_file=report,\n",
    "            json_path=\"metrics.accuracy.value\"\n",
    "        ),\n",
    "        right=accuracy\n",
    "    )\n",
    "\n",
    "\n",
    "gte_approved = gte_eval_condition(eval_model_step, \n",
    "                                eval_winner_report,\n",
    "                                accuracy_threshold)\n",
    "\n",
    "lte_min = lte_eval_condition(eval_model_step,\n",
    "                            eval_winner_report,\n",
    "                            min_accuracy_threshold)\n",
    "\n",
    "\n",
    "gte_min = gte_eval_condition(eval_model_step,\n",
    "                            eval_winner_report,\n",
    "                            min_accuracy_threshold)\n",
    "\n",
    "lte_approved = lte_eval_condition(eval_model_step,\n",
    "                               eval_winner_report,\n",
    "                               accuracy_threshold)\n",
    "\n",
    "fail_step_min = FailStep(\n",
    "    name=\"fail-min\",\n",
    "    error_message=Join(\n",
    "        on=\" \", \n",
    "        values=[\n",
    "            \"Execution failed because the model's accuracy was lower than\", \n",
    "            min_accuracy_threshold\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "def create_condition_step(name, conditions, if_steps, else_steps=None):\n",
    "    return ConditionStep(\n",
    "        name=name,\n",
    "        conditions=conditions,\n",
    "        if_steps=if_steps,\n",
    "        else_steps=else_steps\n",
    "    )\n",
    "\n",
    "# evaluate_tune_min = create_condition_step(\"check-min-accuracy\", [condition_pending_approval_winner, condition_pending_approval_second],[fail_step_min])\n",
    "\n",
    "check_min_step = create_condition_step(\"min-model-accuracy\",\n",
    "                                        [lte_min],\n",
    "                                        [fail_step_min],)\n",
    "\n",
    "approved_step = create_condition_step(\"approved-model-accuracy\", \n",
    "                                        [gte_approved],\n",
    "                                        [register_step_approved])\n",
    "pending_step = create_condition_step(\"pending-model-accuracy\",\n",
    "                                        [lte_approved, gte_min],\n",
    "                                        [register_step_pending],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f70bcd33-b499-4e2b-953e-94d1ed96c10a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:eu-north-1:253909639528:pipeline/penguins-best-model-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': '4325cca4-dff9-4d3c-b76b-dfc47ebc97bc',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4325cca4-dff9-4d3c-b76b-dfc47ebc97bc',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '97',\n",
       "   'date': 'Wed, 20 Sep 2023 17:46:56 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"penguins-best-model-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        accuracy_threshold,\n",
    "        min_accuracy_threshold,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_data_step, \n",
    "        tune_model_step,\n",
    "        eval_model_step,\n",
    "        check_min_step,\n",
    "        approved_step,\n",
    "        pending_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config\n",
    ")\n",
    "pipeline.upsert(role_arn=role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac9cec59-c812-4ca9-9f71-d6725de03c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./code/endpoint'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENDPOINT_CODE_FOLDER = CODE_FOLDER / \"endpoint\"\n",
    "Path(ENDPOINT_CODE_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "sys.path.append(f\"./{ENDPOINT_CODE_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a34c1c1-66af-4cf2-b103-8612bd60ce0e",
   "metadata": {},
   "source": [
    "We will include the inference code as part of the model assets to control the inference process on the SageMaker endpoint. SageMaker will automatically call the `handler()` function for every request to the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57e7ad9e-598b-4e28-9a20-a93ad2bb5f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/endpoint/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {ENDPOINT_CODE_FOLDER}/inference.py\n",
    "\n",
    "from model import PenguinModel\n",
    "\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pickle import load\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def _get_pipeline(directory=None):\n",
    "    \"\"\"\n",
    "    Returns the Scikit-Learn pipeline used to transform the dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if(directory is None):\n",
    "            directory = os.environ.get(\"PREPROCESSING_DIR\", \"/tmp\")\n",
    "        pipeline_directory = Path(directory) / \"pipeline\"\n",
    "        pipeline_file = pipeline_directory / \"pipeline.pkl\"\n",
    "        \n",
    "        if(not pipeline_file.exists()):\n",
    "            pipeline_directory.mkdir(parents=True, exist_ok=True)\n",
    "            _download(pipeline_file)\n",
    "        \n",
    "        return load(open(pipeline_file, 'rb'))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'#lkj Exception: {e}')\n",
    "    \n",
    "\n",
    "def _get_class(prediction, directory):\n",
    "    \"\"\"\n",
    "    Returns the class name of a given prediction. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        if(directory is None):\n",
    "            directory = os.environ.get(\"CLASSES_DIR\", \"/tmp\")\n",
    "        \n",
    "        classes_directory = Path(directory) / \"pipeline\"\n",
    "        classes_file = classes_directory / \"classes.csv\"\n",
    "        \n",
    "        if(not classes_file.exists()):\n",
    "            classes_directory.mkdir(parents=True, exist_ok=True)\n",
    "            _download(classes_file)\n",
    "        \n",
    "        with open(classes_file) as f:\n",
    "            file = f.readlines()\n",
    "\n",
    "        classes = list(map(lambda x: x.replace(\"'\", \"\"), file[0].split(',')))\n",
    "        return classes[prediction]\n",
    "    except Exception as e:\n",
    "        print(f'#lku8 Exception: {e}')\n",
    "\n",
    "\n",
    "def _download(file):    \n",
    "    try:\n",
    "        if(file.exists()):\n",
    "            return\n",
    "\n",
    "        s3_uri = os.environ.get(\"S3_LOCATION\", f\"s3://vmate-mlschool4/penguins/preprocessing\")\n",
    "\n",
    "        s3_parts = s3_uri.split('/', 3)\n",
    "        bucket = s3_parts[2]\n",
    "        key = s3_parts[3]\n",
    "\n",
    "        s3.Bucket(bucket).download_file(f\"{key}/{file.name}\", str(file))\n",
    "    except Exception as e:\n",
    "        print(f'#kljkl Exception: {e}')\n",
    "\n",
    "        \n",
    "    \n",
    "def _process_probabilities(probabilities):\n",
    "    \"\"\"\n",
    "        Returns class and probability\n",
    "    \"\"\"\n",
    "    prediction = np.argmax(probabilities)    \n",
    "    confidence = probabilities[prediction]\n",
    "    return prediction, confidence\n",
    "    \n",
    "def _process_prediction(input_data,groundtruth,directory):\n",
    "    \"\"\"\n",
    "        Return prediction in JSON format and groundtruth(undesirable hack to generate baseline stats and data)\n",
    "    \"\"\" \n",
    "    prediction, confidence = input_data\n",
    "    species = _get_class(prediction, directory)\n",
    "    result =  {\n",
    "        \"species\": species,\n",
    "        \"prediction\": int(prediction),\n",
    "        \"confidence\": confidence.item()\n",
    "    } \n",
    "\n",
    "    # A hack as a workaround\n",
    "    # https://github.com/aws/sagemaker-python-sdk/issues/4130\n",
    "    if groundtruth:\n",
    "        result[\"groundtruth\"] = groundtruth\n",
    "    \n",
    "    return result\n",
    "    \n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "        Loads Pytorch model\n",
    "    \"\"\"\n",
    "    input_shape = 7\n",
    "    \n",
    "    model = PenguinModel(input_shape=input_shape)    \n",
    "    try:\n",
    "        with open(Path(model_dir) / '001' / 'model.pth', 'rb') as f:\n",
    "            model.load_state_dict(torch.load(f))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"#kj9 Exception: {e}\")\n",
    "         \n",
    "    return model\n",
    "    \n",
    "def input_fn(request_body, request_content_type, directory=None):\n",
    "    \n",
    "    print(f\"Processing input data...{request_body}\")\n",
    "    try:\n",
    "        if request_content_type in (\"application/json\", \"application/octet-stream\"):\n",
    "            # When the endpoint is running, we will receive a context\n",
    "            # object. We need to parse the input and turn it into \n",
    "            # JSON in that case.\n",
    "            endpoint_input = json.loads(request_body)\n",
    "            if isinstance(endpoint_input, dict):\n",
    "                endpoint_input = [endpoint_input]                \n",
    "            print(f'JSON: {endpoint_input}')\n",
    "            if endpoint_input is None:\n",
    "                raise ValueError(\"There was an error parsing the input request.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported content type: {request_content_type or 'unknown'}\")\n",
    "        # As a work around a bug in QualityCheckStep when using JSONPath(s).\n",
    "        # We counter-intuitively send the groundtruth from test data to calculate baseline performance.\n",
    "        # \n",
    "        # https://github.com/aws/sagemaker-python-sdk/issues/4130\n",
    "        pipeline = _get_pipeline(directory)\n",
    "        transformed_data = []\n",
    "        \n",
    "        for data in endpoint_input:\n",
    "            groundtruth = data.pop(\"species\", None)\n",
    "            df = pd.json_normalize(data)\n",
    "            result = pipeline.transform(df)\n",
    "            tensor = torch.tensor(result, dtype=torch.float32)\n",
    "            transformed_data.append((tensor,groundtruth))\n",
    "        return transformed_data\n",
    "    except Exception as e:\n",
    "        print(f\"#k88jj Exception: {e}\")\n",
    "    \n",
    "\n",
    "def predict_fn(input_data_list, model):\n",
    "    print(f\"Sending input data to model to make a prediction...\")\n",
    "    results = []\n",
    "    for data in input_data_list:\n",
    "        tensor, groundtruth = data\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            out = model.predict(tensor)\n",
    "        results.append((out,groundtruth))\n",
    "    return results\n",
    "    \n",
    "def output_fn(output_data, directory=None, accept=\"application/json\"):\n",
    "    print(\"Processing prediction received from the model...\")\n",
    "    prediction_list = []\n",
    "    for output in output_data:\n",
    "        predictions, groundtruth = output\n",
    "        result = _process_probabilities(predictions[0])\n",
    "        prediction = _process_prediction(result,groundtruth,directory)\n",
    "        prediction_list.append(prediction)\n",
    "    \n",
    "    if accept == 'application/json':\n",
    "        return json.dumps(prediction_list), accept\n",
    "    \n",
    "    raise Exception(f'Requested unsupported ContentType in Accept:{accept}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13b4530a-5349-46eb-ad44-675fe50f3446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] - loss: 1.1031, val_accuracy: 0.1883\n",
      "Epoch [2/50] - loss: 1.1021, val_accuracy: 0.1883\n",
      "Epoch [3/50] - loss: 1.1011, val_accuracy: 0.1883\n",
      "Epoch [4/50] - loss: 1.1001, val_accuracy: 0.1925\n",
      "Epoch [5/50] - loss: 1.0991, val_accuracy: 0.2050\n",
      "Epoch [6/50] - loss: 1.0980, val_accuracy: 0.2176\n",
      "Epoch [7/50] - loss: 1.0970, val_accuracy: 0.2385\n",
      "Epoch [8/50] - loss: 1.0960, val_accuracy: 0.2845\n",
      "Epoch [9/50] - loss: 1.0949, val_accuracy: 0.3054\n",
      "Epoch [10/50] - loss: 1.0938, val_accuracy: 0.3473\n",
      "Epoch [11/50] - loss: 1.0928, val_accuracy: 0.3849\n",
      "Epoch [12/50] - loss: 1.0917, val_accuracy: 0.4393\n",
      "Epoch [13/50] - loss: 1.0906, val_accuracy: 0.4644\n",
      "Epoch [14/50] - loss: 1.0895, val_accuracy: 0.4937\n",
      "Epoch [15/50] - loss: 1.0884, val_accuracy: 0.5439\n",
      "Epoch [16/50] - loss: 1.0872, val_accuracy: 0.5690\n",
      "Epoch [17/50] - loss: 1.0861, val_accuracy: 0.5983\n",
      "Epoch [18/50] - loss: 1.0849, val_accuracy: 0.6025\n",
      "Epoch [19/50] - loss: 1.0837, val_accuracy: 0.6067\n",
      "Epoch [20/50] - loss: 1.0825, val_accuracy: 0.6025\n",
      "Epoch [21/50] - loss: 1.0813, val_accuracy: 0.6109\n",
      "Epoch [22/50] - loss: 1.0801, val_accuracy: 0.5983\n",
      "Epoch [23/50] - loss: 1.0788, val_accuracy: 0.5941\n",
      "Epoch [24/50] - loss: 1.0775, val_accuracy: 0.5816\n",
      "Epoch [25/50] - loss: 1.0762, val_accuracy: 0.5816\n",
      "Epoch [26/50] - loss: 1.0749, val_accuracy: 0.5690\n",
      "Epoch [27/50] - loss: 1.0735, val_accuracy: 0.5649\n",
      "Epoch [28/50] - loss: 1.0722, val_accuracy: 0.5649\n",
      "Epoch [29/50] - loss: 1.0708, val_accuracy: 0.5565\n",
      "Epoch [30/50] - loss: 1.0694, val_accuracy: 0.5523\n",
      "Epoch [31/50] - loss: 1.0679, val_accuracy: 0.5481\n",
      "Epoch [32/50] - loss: 1.0664, val_accuracy: 0.5439\n",
      "Epoch [33/50] - loss: 1.0649, val_accuracy: 0.5397\n",
      "Epoch [34/50] - loss: 1.0634, val_accuracy: 0.5314\n",
      "Epoch [35/50] - loss: 1.0618, val_accuracy: 0.5105\n",
      "Epoch [36/50] - loss: 1.0602, val_accuracy: 0.5063\n",
      "Epoch [37/50] - loss: 1.0586, val_accuracy: 0.5021\n",
      "Epoch [38/50] - loss: 1.0569, val_accuracy: 0.4895\n",
      "Epoch [39/50] - loss: 1.0552, val_accuracy: 0.4812\n",
      "Epoch [40/50] - loss: 1.0534, val_accuracy: 0.4770\n",
      "Epoch [41/50] - loss: 1.0517, val_accuracy: 0.4644\n",
      "Epoch [42/50] - loss: 1.0498, val_accuracy: 0.4603\n",
      "Epoch [43/50] - loss: 1.0480, val_accuracy: 0.4561\n",
      "Epoch [44/50] - loss: 1.0461, val_accuracy: 0.4519\n",
      "Epoch [45/50] - loss: 1.0441, val_accuracy: 0.4519\n",
      "Epoch [46/50] - loss: 1.0421, val_accuracy: 0.4519\n",
      "Epoch [47/50] - loss: 1.0401, val_accuracy: 0.4519\n",
      "Epoch [48/50] - loss: 1.0380, val_accuracy: 0.4519\n",
      "Epoch [49/50] - loss: 1.0359, val_accuracy: 0.4519\n",
      "Epoch [50/50] - loss: 1.0337, val_accuracy: 0.4519\n",
      "Model saved: /tmp/tmpeiyj6uro/model/001/model.pth\n",
      "model_fn: Loading model ...\n",
      "/tmp/tmpeiyj6uro/model/001\n",
      "/tmp/tmpeiyj6uro/model/001/model.pth\n",
      "Processing input data...{\"island\": \"Biscoe\", \"culmen_length_mm\": 18.6, \"culmen_depth_mm\": 16.0, \"flipper_length_mm\": 230.0, \"body_mass_g\": 1800.0, \"species\": \"jkhkj\"}\n",
      "JSON: [{'island': 'Biscoe', 'culmen_length_mm': 18.6, 'culmen_depth_mm': 16.0, 'flipper_length_mm': 230.0, 'body_mass_g': 1800.0, 'species': 'jkhkj'}]\n",
      "DATA: {'island': 'Biscoe', 'culmen_length_mm': 18.6, 'culmen_depth_mm': 16.0, 'flipper_length_mm': 230.0, 'body_mass_g': 1800.0, 'species': 'jkhkj'}\n",
      "Sending input data to model to make a prediction...\n",
      "Processing prediction received from the model...\n",
      "('[{\"species\": \"Adelie\", \"prediction\": 0, \"confidence\": 0.6827392578125, \"groundtruth\": \"jkhkj\"}]', 'application/json')\n"
     ]
    }
   ],
   "source": [
    "samples = {\n",
    "    \"island\": \"Biscoe\",\n",
    "    \"culmen_length_mm\": 18.6,\n",
    "    \"culmen_depth_mm\": 16.0,\n",
    "    \"flipper_length_mm\": 230.0,\n",
    "    \"body_mass_g\": 1800.0,\n",
    "    \"species\": \"jkhkj\"\n",
    "}\n",
    "with tempfile.TemporaryDirectory() as directory:\n",
    "    \n",
    "    preprocess(\n",
    "        base_directory=directory, \n",
    "        data_filepath=DATA_FILEPATH\n",
    "    )\n",
    "\n",
    "    train(\n",
    "        base_directory=directory, \n",
    "        train_path=Path(directory) / \"train\", \n",
    "        validation_path=Path(directory) / \"validation\",\n",
    "        epochs=50\n",
    "    )\n",
    "    \n",
    "    request_content_type = \"application/json\"\n",
    "    \n",
    "    # for sample in samples:\n",
    "    #     # handler = Handler() \n",
    "    model = model_fn(Path(directory) / \"model\")\n",
    "    transformed_list = input_fn(json.dumps(samples), request_content_type, directory)\n",
    "    # print(transformed_list)\n",
    "    output_np = predict_fn(transformed_list, model)\n",
    "    # print(output_np)\n",
    "    predictions = output_fn(output_np,directory)\n",
    "    print(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e2c6d-977e-43ec-98d4-ec66781af582",
   "metadata": {},
   "source": [
    "SageMaker's default TensorFlow inference container doesn't come with Scikit-Learn installed, so we need to provide a `requirements.txt` file with the libraries we want SageMaker to install in our endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed40d098-d553-4d56-b2eb-f80cec420ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/endpoint/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {ENDPOINT_CODE_FOLDER}/requirements.txt\n",
    "\n",
    "numpy==1.19.5\n",
    "pandas==1.1.5\n",
    "scikit-learn==0.23.2\n",
    "boto3\n",
    "sagemaker_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afa8f28e-29fe-4694-815c-bc5fed19feec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py:297: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "repacked_model = PyTorchModel(\n",
    "    name=\"penguins\",\n",
    "    model_data=(\n",
    "        tune_model_step.get_top_model_s3_uri(top_k=0, s3_bucket=PipelineSession().default_bucket())\n",
    "    ),\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    sagemaker_session=PipelineSession(),\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=str(ENDPOINT_CODE_FOLDER),\n",
    "    env={\n",
    "        \"PIPELINE_S3_LOCATION\": Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\"pipeline\"].S3Output.S3Uri,\n",
    "                \"pipeline.pkl\",\n",
    "            ]\n",
    "        ),\n",
    "        \"CLASSES_S3_LOCATION\": Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\"classes\"].S3Output.S3Uri,\n",
    "                \"classes.csv\",\n",
    "            ]\n",
    "        )\n",
    "    }    \n",
    ")\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name=\"register\",\n",
    "    display_name=\"register-model\",\n",
    "    step_args=repacked_model.register(\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        approval_status=\"Approved\",\n",
    "        content_types=[\"application/json\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"PYTORCH\",\n",
    "        framework_version=\"1.8\",\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ba0ffbb-7177-4b3c-923a-732dd6e81b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint does not exist\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = boto3.client(\"sagemaker\").delete_endpoint(\n",
    "        EndpointName=\"penguins-endpoint\",\n",
    "    )\n",
    "    \n",
    "    response = boto3.client(\"sagemaker\").delete_endpoint_config(\n",
    "        EndpointConfigName='penguins-endpoint'\n",
    "    )\n",
    "except:\n",
    "    print(\"Endpoint does not exist\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b87783ce-06e0-4da2-9c0b-70ac58ef7fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: penguins-2023-09-20-13-40-48-432\n",
      "INFO:sagemaker:Creating endpoint-config with name test-endpoint\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateEndpointConfig operation: Cannot create already existing endpoint configuration \"arn:aws:sagemaker:eu-north-1:253909639528:endpoint-config/test-endpoint\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-14254a88ba9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m model_package.deploy(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test-endpoint'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0minitial_instance_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mexplainer_config_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_request_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m         self.sagemaker_session.endpoint_from_production_variants(\n\u001b[0m\u001b[1;32m   1411\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m             \u001b[0mproduction_variants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproduction_variant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict, explainer_config_dict)\u001b[0m\n\u001b[1;32m   4688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4689\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating endpoint-config with name %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4692\u001b[0m         return self.create_endpoint(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 )\n\u001b[1;32m    534\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateEndpointConfig operation: Cannot create already existing endpoint configuration \"arn:aws:sagemaker:eu-north-1:253909639528:endpoint-config/test-endpoint\"."
     ]
    }
   ],
   "source": [
    "response = sagemaker_client.list_model_packages(\n",
    "    ModelPackageGroupName=MODEL_PACKAGE_GROUP,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    "    SortBy=\"CreationTime\",\n",
    "    MaxResults=1,\n",
    ")\n",
    "\n",
    "package = response[\"ModelPackageSummaryList\"][0] if response[\"ModelPackageSummaryList\"] else None\n",
    "package\n",
    "\n",
    "model_package = ModelPackage(\n",
    "    model_package_arn=package[\"ModelPackageArn\"], \n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role, \n",
    ")\n",
    "\n",
    "model_package.deploy(\n",
    "    endpoint_name='test-endpoint', \n",
    "    initial_instance_count=1, \n",
    "    instance_type=\"ml.m5.large\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28c75afd-d0d0-47f4-b7b6-9d590c5b600e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/lambda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CODE_FOLDER}/lambda.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    model_package_arn = event[\"model_package_arn\"]\n",
    "    endpoint_name = event[\"endpoint_name\"]\n",
    "    data_capture_percentage = event[\"data_capture_percentage\"]\n",
    "    data_capture_destination = event[\"data_capture_destination\"]\n",
    "    role = event[\"role\"]\n",
    "    timestamp = time.strftime(\"%m%d%H%M%S\", time.localtime())\n",
    "    model_name = f\"penguins-model-{timestamp}\"\n",
    "    endpoint_config_name = f\"penguins-endpoint-config-{timestamp}\"\n",
    "\n",
    "    sagemaker.create_model(\n",
    "        ModelName=model_name, \n",
    "        ExecutionRoleArn=role, \n",
    "        Containers=[{\n",
    "            \"ModelPackageName\": model_package_arn\n",
    "        }] \n",
    "    )\n",
    "\n",
    "    sagemaker.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"ModelName\": model_name,\n",
    "                \"InstanceType\": \"ml.m5.large\",\n",
    "                \"InitialVariantWeight\": 1,\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "            }\n",
    "        ],\n",
    "        DataCaptureConfig={\n",
    "            \"EnableCapture\": True,\n",
    "            \"InitialSamplingPercentage\": data_capture_percentage,\n",
    "            \"DestinationS3Uri\": data_capture_destination,\n",
    "            \"CaptureOptions\": [\n",
    "                {\n",
    "                    'CaptureMode': \"Input\"\n",
    "                },\n",
    "                {\n",
    "                    'CaptureMode': \"Output\"\n",
    "                },\n",
    "            ],\n",
    "            \"CaptureContentTypeHeader\": {\n",
    "                \"JsonContentTypes\": [\n",
    "                    \"application/json\",\n",
    "                    \"application/octect-stream\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    sagemaker.create_endpoint(\n",
    "        EndpointName=endpoint_name, \n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps(\"Endpoint deployed successfully\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9941979-c085-4ef9-8c66-908378d89a91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lambda_role(role_name):\n",
    "    try:\n",
    "        response = iam_client.create_role(\n",
    "            RoleName = role_name,\n",
    "            AssumeRolePolicyDocument = json.dumps({\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\n",
    "                            \"Service\": \"lambda.amazonaws.com\"\n",
    "                        },\n",
    "                        \"Action\": \"sts:AssumeRole\"\n",
    "                    }\n",
    "                ]\n",
    "            }),\n",
    "            Description=\"Lambda Pipeline Role\"\n",
    "        )\n",
    "\n",
    "        role_arn = response['Role']['Arn']\n",
    "\n",
    "        iam_client.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
    "        )\n",
    "\n",
    "        iam_client.attach_role_policy(\n",
    "            PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess',\n",
    "            RoleName=role_name\n",
    "        )\n",
    "\n",
    "        return role_arn\n",
    "\n",
    "    except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "        response = iam_client.get_role(RoleName=role_name)\n",
    "        return response['Role']['Arn']\n",
    "\n",
    "\n",
    "lambda_role = create_lambda_role(\"lambda-pipeline-role\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c6eda89-70f3-49b4-8983-90f4db72fd02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_capture_percentage = ParameterInteger(\n",
    "    name=\"data_capture_percentage\",\n",
    "    default_value=100,\n",
    ")\n",
    "\n",
    "data_capture_destination = ParameterString(\n",
    "    name=\"data_capture_destination\",\n",
    "    default_value=f\"{S3_LOCATION}/monitoring/data-capture\",\n",
    ")\n",
    "\n",
    "deploy_fn = Lambda(\n",
    "    function_name=\"deploy_fn\",\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=str(CODE_FOLDER / \"lambda.py\"),\n",
    "    handler=\"lambda.lambda_handler\",\n",
    "    timeout=600\n",
    ")\n",
    "\n",
    "deploy_fn.upsert()\n",
    "\n",
    "deploy_step = LambdaStep(\n",
    "    name=\"deploy\",\n",
    "    lambda_func=deploy_fn,\n",
    "    inputs={\n",
    "        # We use the ARN of the model we registered to\n",
    "        # deploy it to the endpoint.\n",
    "        \"model_package_arn\": register_model_step.properties.ModelPackageArn,\n",
    "\n",
    "        \"endpoint_name\": \"penguins-endpoint\",\n",
    "        \n",
    "        \"data_capture_percentage\": data_capture_percentage,\n",
    "        \"data_capture_destination\": data_capture_destination,\n",
    "        \n",
    "        \"role\": role,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c7e2f9d-cc75-46bc-8700-f7123292fac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_QUALITY_LOCATION = f\"{S3_LOCATION}/monitoring/data-quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f35e8db-24d7-4d4b-9264-78ee5070cf27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://vmate-mlschool4/penguins/monitoring/data-capture/penguins-endpoint/AllTraffic/2023/09/18/09/49-19-796-eff58838-efde-4890-89ec-8b0e6ca7d7fc.jsonl',\n",
       " 's3://vmate-mlschool4/penguins/monitoring/data-capture/penguins-endpoint/AllTraffic/2023/09/18/11/11-32-485-70a9b20c-2b10-43cf-9d6d-866a1a28fc12.jsonl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = S3Downloader.list(data_capture_destination.default_value)[:3]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dee0107-c9ca-4f75-873d-d47512c56797",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"captureData\": {\n",
      "    \"endpointInput\": {\n",
      "      \"observedContentType\": \"application/octet-stream\",\n",
      "      \"mode\": \"INPUT\",\n",
      "      \"data\": \"W3siaXNsYW5kIjogIkJpc2NvZSIsICJjdWxtZW5fbGVuZ3RoX21tIjogNDguNiwgImN1bG1lbl9kZXB0aF9tbSI6IDE2LjAsICJmbGlwcGVyX2xlbmd0aF9tbSI6IDIzMC4wLCAiYm9keV9tYXNzX2ciOiA1ODAwLjB9LCB7ImlzbGFuZCI6ICJEcmVhbSIsICJjdWxtZW5fbGVuZ3RoX21tIjogNDMuMiwgImN1bG1lbl9kZXB0aF9tbSI6IDE3LjUsICJmbGlwcGVyX2xlbmd0aF9tbSI6IDE3NS4wLCAiYm9keV9tYXNzX2ciOiAzNTAwLjB9LCB7ImlzbGFuZCI6ICJUb3JnZXJzZW4iLCAiY3VsbWVuX2xlbmd0aF9tbSI6IDM4LjYsICJjdWxtZW5fZGVwdGhfbW0iOiAxNi4wLCAiZmxpcHBlcl9sZW5ndGhfbW0iOiAxNzYuMCwgImJvZHlfbWFzc19nIjogMzcwMC4wfV0=\",\n",
      "      \"encoding\": \"BASE64\"\n",
      "    },\n",
      "    \"endpointOutput\": {\n",
      "      \"observedContentType\": \"application/json\",\n",
      "      \"mode\": \"OUTPUT\",\n",
      "      \"data\": \"[{\\\"species\\\": null, \\\"prediction\\\": 2, \\\"confidence\\\": 0.9935439825057983}, {\\\"species\\\": null, \\\"prediction\\\": 0, \\\"confidence\\\": 0.9356141686439514}, {\\\"species\\\": null, \\\"prediction\\\": 0, \\\"confidence\\\": 0.9818596243858337}]\",\n",
      "      \"encoding\": \"JSON\"\n",
      "    }\n",
      "  },\n",
      "  \"eventMetadata\": {\n",
      "    \"eventId\": \"0a1668a0-e868-45c9-a5f5-0dd3481cf4ac\",\n",
      "    \"inferenceTime\": \"2023-09-18T09:49:19Z\"\n",
      "  },\n",
      "  \"eventVersion\": \"0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if len(files):\n",
    "    lines = S3Downloader.read_file(files[0])\n",
    "    print(json.dumps(json.loads(lines.split(\"\\n\")[0]), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b80bcab-d2c5-437c-a1c8-8eea208c0e29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "data_quality_baseline_step = QualityCheckStep(\n",
    "    name=\"generate-data-quality-baseline\",\n",
    "    \n",
    "    check_job_config = CheckJobConfig(\n",
    "        instance_type=\"ml.t3.xlarge\",\n",
    "        instance_count=1,\n",
    "        volume_size_in_gb=20,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    "    ),\n",
    "    \n",
    "    quality_check_config = DataQualityCheckConfig(\n",
    "        # We will use the train dataset we generated during the preprocessing \n",
    "        # step to generate the data quality baseline.\n",
    "        baseline_dataset=preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\"train-baseline\"].S3Output.S3Uri,\n",
    "\n",
    "        dataset_format=DatasetFormat.json(lines=True),\n",
    "        output_s3_uri=DATA_QUALITY_LOCATION\n",
    "    ),\n",
    "    \n",
    "    skip_check=True,\n",
    "    register_new_baseline=True,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15deceeb-80f4-483e-a6b2-126ad94aff5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"captureData\": {\n",
      "    \"endpointInput\": {\n",
      "      \"observedContentType\": \"application/octet-stream\",\n",
      "      \"mode\": \"INPUT\",\n",
      "      \"data\": \"W3siaXNsYW5kIjogIkJpc2NvZSIsICJjdWxtZW5fbGVuZ3RoX21tIjogNDguNiwgImN1bG1lbl9kZXB0aF9tbSI6IDE2LjAsICJmbGlwcGVyX2xlbmd0aF9tbSI6IDIzMC4wLCAiYm9keV9tYXNzX2ciOiA1ODAwLjB9LCB7ImlzbGFuZCI6ICJEcmVhbSIsICJjdWxtZW5fbGVuZ3RoX21tIjogNDMuMiwgImN1bG1lbl9kZXB0aF9tbSI6IDE3LjUsICJmbGlwcGVyX2xlbmd0aF9tbSI6IDE3NS4wLCAiYm9keV9tYXNzX2ciOiAzNTAwLjB9LCB7ImlzbGFuZCI6ICJUb3JnZXJzZW4iLCAiY3VsbWVuX2xlbmd0aF9tbSI6IDM4LjYsICJjdWxtZW5fZGVwdGhfbW0iOiAxNi4wLCAiZmxpcHBlcl9sZW5ndGhfbW0iOiAxNzYuMCwgImJvZHlfbWFzc19nIjogMzcwMC4wfV0=\",\n",
      "      \"encoding\": \"BASE64\"\n",
      "    },\n",
      "    \"endpointOutput\": {\n",
      "      \"observedContentType\": \"application/json\",\n",
      "      \"mode\": \"OUTPUT\",\n",
      "      \"data\": \"[{\\\"species\\\": null, \\\"prediction\\\": 2, \\\"confidence\\\": 0.9935439825057983}, {\\\"species\\\": null, \\\"prediction\\\": 0, \\\"confidence\\\": 0.9356141686439514}, {\\\"species\\\": null, \\\"prediction\\\": 0, \\\"confidence\\\": 0.9818596243858337}]\",\n",
      "      \"encoding\": \"JSON\"\n",
      "    }\n",
      "  },\n",
      "  \"eventMetadata\": {\n",
      "    \"eventId\": \"0a1668a0-e868-45c9-a5f5-0dd3481cf4ac\",\n",
      "    \"inferenceTime\": \"2023-09-18T09:49:19Z\"\n",
      "  },\n",
      "  \"eventVersion\": \"0\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "Using provided s3_resource\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "Using provided s3_resource\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_PipelineExecution(arn='arn:aws:sagemaker:eu-north-1:253909639528:pipeline/penguins-session6-pipeline-test/execution/7dde56ujhzsd', sagemaker_session=<sagemaker.workflow.pipeline_context.PipelineSession object at 0x7f9c06229be0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GROUND_TRUTH_LOCATION = f\"{S3_LOCATION}/monitoring/groundtruth\"\n",
    "DATA_QUALITY_LOCATION = f\"{S3_LOCATION}/monitoring/data-quality\"\n",
    "MODEL_QUALITY_LOCATION = f\"{S3_LOCATION}/monitoring/model-quality\"\n",
    "\n",
    "files = S3Downloader.list(data_capture_destination.default_value)[:3]\n",
    "files\n",
    "\n",
    "if len(files):\n",
    "    lines = S3Downloader.read_file(files[0])\n",
    "    print(json.dumps(json.loads(lines.split(\"\\n\")[0]), indent=2))\n",
    "    \n",
    "data_quality_baseline_step = QualityCheckStep(\n",
    "    name=\"generate-data-quality-baseline\",\n",
    "    \n",
    "    check_job_config = CheckJobConfig(\n",
    "        instance_type=\"ml.t3.large\",\n",
    "        instance_count=1,\n",
    "        volume_size_in_gb=20,\n",
    "        sagemaker_session=PipelineSession(),\n",
    "        role=role,\n",
    "    ),\n",
    "    \n",
    "    quality_check_config = DataQualityCheckConfig(\n",
    "        # We will use the train dataset we generated during the preprocessing \n",
    "        # step to generate the data quality baseline.\n",
    "        baseline_dataset=preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\"train-baseline\"].S3Output.S3Uri,\n",
    "\n",
    "        dataset_format=DatasetFormat.json(lines=True),\n",
    "        output_s3_uri=DATA_QUALITY_LOCATION\n",
    "    ),\n",
    "    \n",
    "    skip_check=True,\n",
    "    register_new_baseline=True,\n",
    "    model_package_group_name=MODEL_PACKAGE_GROUP,\n",
    "    cache_config=cache_config\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "create_model_step = ModelStep(\n",
    "    name=\"create\",\n",
    "    display_name=\"create-model\",\n",
    "    step_args=repacked_model.create(\n",
    "        instance_type=\"ml.m5.large\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=create_model_step.properties.ModelName,\n",
    "    base_transform_job_name=\"transform\",\n",
    "\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    \n",
    "    accept=\"application/json\",\n",
    "    strategy=\"SingleRecord\",\n",
    "    assemble_with=\"Line\",\n",
    "    \n",
    "    output_path=f\"{S3_LOCATION}/transform\",\n",
    "    sagemaker_session=PipelineSession()\n",
    ")\n",
    "\n",
    "generate_test_predictions_step = TransformStep(\n",
    "    name=\"generate-test-predictions\",\n",
    "    step_args=transformer.transform(\n",
    "        # We will use the test dataset we generated during the preprocessing \n",
    "        # step to run it through the model and generate predictions.\n",
    "        data=preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\"test-baseline\"].S3Output.S3Uri,\n",
    "\n",
    "        join_source=\"Input\",\n",
    "        content_type=\"application/json\",\n",
    "        split_type=\"Line\",\n",
    "        output_filter=\"$.SageMakerOutput['prediction','groundtruth']\",\n",
    "    ),\n",
    "    cache_config=cache_config\n",
    ")\n",
    "\n",
    "model_quality_location = f\"{S3_LOCATION}/monitoring/model-quality\"\n",
    "\n",
    "model_quality_baseline_step = QualityCheckStep(\n",
    "    name=\"generate-model-quality-baseline\",\n",
    "    \n",
    "    check_job_config = CheckJobConfig(\n",
    "        instance_type=\"ml.t3.xlarge\",\n",
    "        instance_count=1,\n",
    "        volume_size_in_gb=20,\n",
    "        sagemaker_session=PipelineSession(),\n",
    "        role=role,\n",
    "    ),\n",
    "    \n",
    "    quality_check_config = ModelQualityCheckConfig(\n",
    "        # We are going to use the output of the Transform Step to generate\n",
    "        # the model quality baseline.\n",
    "        baseline_dataset=generate_test_predictions_step.properties.TransformOutput.S3OutputPath,\n",
    "\n",
    "        dataset_format=DatasetFormat.json(lines=True),\n",
    "\n",
    "        # We need to specify the problem type and the fields where the prediction\n",
    "        # and groundtruth are so the process knows how to interpret the results.\n",
    "        problem_type=\"MulticlassClassification\",\n",
    "        inference_attribute=\"prediction\",\n",
    "        ground_truth_attribute=\"groundtruth\",\n",
    "\n",
    "        output_s3_uri=model_quality_location,\n",
    "    ),\n",
    "    \n",
    "    skip_check=True,\n",
    "    register_new_baseline=True,\n",
    "    model_package_group_name=MODEL_PACKAGE_GROUP,\n",
    "    cache_config=cache_config\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    \n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "register_model_step = ModelStep(\n",
    "    name=\"register\",\n",
    "    display_name=\"register-model\",\n",
    "    step_args=repacked_model.register(\n",
    "        model_package_group_name=MODEL_PACKAGE_GROUP,\n",
    "        model_metrics=model_metrics,\n",
    "        approval_status=\"Approved\",\n",
    "        content_types=[\"application/json\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"PYTORCH\",\n",
    "        framework_version=\"1.8\",\n",
    "    )\n",
    ")\n",
    "\n",
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[gte_approved],\n",
    "    if_steps=[\n",
    "        create_model_step, \n",
    "        generate_test_predictions_step, \n",
    "        model_quality_baseline_step, \n",
    "        register_model_step,\n",
    "        deploy_step\n",
    "    ],\n",
    "    else_steps=[fail_step_min], \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1987a788-de7a-4f60-ac8d-819d9ffcdf8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_model_step = ModelStep(\n",
    "    name=\"create\",\n",
    "    display_name=\"create-model\",\n",
    "    step_args=repacked_model.create(\n",
    "        instance_type=\"ml.m5.large\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=create_model_step.properties.ModelName,\n",
    "    base_transform_job_name=\"transform\",\n",
    "\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    \n",
    "    accept=\"application/json\",\n",
    "    strategy=\"SingleRecord\",\n",
    "    assemble_with=\"Line\",\n",
    "    \n",
    "    output_path=f\"{S3_LOCATION}/transform\",\n",
    ")\n",
    "\n",
    "# Workaround for bug in SDK version 2.171.0\n",
    "# https://github.com/aws/sagemaker-python-sdk/issues/3991\n",
    "transformer._current_job_name = \"transform\"\n",
    "\n",
    "generate_test_predictions_step = TransformStep(\n",
    "    name=\"generate-test-predictions\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(\n",
    "        \n",
    "        # We will use the test dataset we generated during the preprocessing \n",
    "        # step to run it through the model and generate predictions.\n",
    "        data=preprocess_data_step.properties.ProcessingOutputConfig.Outputs[\"test-baseline\"].S3Output.S3Uri,\n",
    "\n",
    "        join_source=\"Input\",\n",
    "        content_type=\"application/json\",\n",
    "        split_type=\"Line\",\n",
    "    ),\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9aa3a284-8763-4000-a263-70314b530652",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: .\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "model_quality_location = f\"{S3_LOCATION}/monitoring/model-quality\"\n",
    "\n",
    "model_quality_baseline_step = QualityCheckStep(\n",
    "    name=\"generate-model-quality-baseline\",\n",
    "    \n",
    "    check_job_config = CheckJobConfig(\n",
    "        instance_type=\"ml.t3.xlarge\",\n",
    "        instance_count=1,\n",
    "        volume_size_in_gb=20,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    "    ),\n",
    "    \n",
    "    quality_check_config = ModelQualityCheckConfig(\n",
    "        # We are going to use the output of the Transform Step to generate\n",
    "        # the model quality baseline.\n",
    "        baseline_dataset=generate_test_predictions_step.properties.TransformOutput.S3OutputPath,\n",
    "\n",
    "        dataset_format=DatasetFormat.json(lines=True),\n",
    "\n",
    "        # We need to specify the problem type and the fields where the prediction\n",
    "        # and groundtruth are so the process knows how to interpret the results.\n",
    "        problem_type=\"MulticlassClassification\",\n",
    "        inference_attribute=\"$['SageMakerOutput'][*]['species']\",\n",
    "        ground_truth_attribute=\"species\",\n",
    "\n",
    "        output_s3_uri=model_quality_location,\n",
    "    ),\n",
    "    \n",
    "    skip_check=True,\n",
    "    register_new_baseline=True,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a773f134-ac2f-4dba-976e-9b7f0b384b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    \n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "drift_check_baselines = DriftCheckBaselines(\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30cd6953-19db-4254-829a-0fd4f78f5315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "register_model_step = ModelStep(\n",
    "    name=\"register\",\n",
    "    display_name=\"register-model\",\n",
    "    step_args=repacked_model.register(\n",
    "        model_package_group_name=model_package_group_name,\n",
    "        model_metrics=model_metrics,\n",
    "        drift_check_baselines=drift_check_baselines,\n",
    "        approval_status=\"Approved\",\n",
    "        content_types=[\"application/json\"],\n",
    "        response_types=[\"application/json\"],\n",
    "        inference_instances=[\"ml.m5.large\"],\n",
    "        domain=\"MACHINE_LEARNING\",\n",
    "        task=\"CLASSIFICATION\",\n",
    "        framework=\"PYTORCH\",\n",
    "        framework_version=\"1.8\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bacaa9c6-22b0-48df-b138-95b6422fe834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-accuracy\",\n",
    "    conditions=[gte_approved],\n",
    "    if_steps=[\n",
    "        create_model_step, \n",
    "        generate_test_predictions_step,\n",
    "        model_quality_baseline_step,\n",
    "        register_model_step,\n",
    "        deploy_step\n",
    "    ],\n",
    "    else_steps=[fail_step_min], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4da5e453-acd8-47a0-a39f-264d05dd93d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_capture_percentage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d7571d69dfb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdataset_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpreprocessor_destination\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdata_capture_percentage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mdata_capture_destination\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0maccuracy_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_capture_percentage' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"final-penguins-pipeline\",\n",
    "    parameters=[\n",
    "        dataset_location, \n",
    "        preprocessor_destination,\n",
    "        data_capture_percentage,\n",
    "        data_capture_destination,\n",
    "        accuracy_threshold,\n",
    "        min_accuracy_threshold,\n",
    "    ],\n",
    "    steps=[\n",
    "        preprocess_data_step,\n",
    "        data_quality_baseline_step,\n",
    "        tune_model_step,\n",
    "        eval_model_step,\n",
    "        condition_step,         \n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config\n",
    ")\n",
    "\n",
    "pipeline.upsert(role_arn=role)\n",
    "\n",
    "# Delete endpoint(if already exists) as Pipeline will fail on the Lambda step(deployment)\n",
    "try:\n",
    "    response = boto3.client(\"sagemaker\").delete_endpoint(\n",
    "        EndpointName=\"penguins-endpoint\",\n",
    "    )\n",
    "except:\n",
    "    print(\"Endpoint does not exist\")\n",
    "    \n",
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01d0caaa-ffc8-49a9-a650-222cab325d08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[{\"species\": \"Gentoo\", \"prediction\": 2, \"confidence\": 0.9731643795967102}, {\"species\": \"Adelie\", \"prediction\": 0, \"confidence\": 0.9101532697677612}, {\"species\": \"Adelie\", \"prediction\": 0, \"confidence\": 0.9595704674720764}]'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "endpoint = 'penguins-endpoint'\n",
    "\n",
    "# Read image into memory\n",
    "payload=[{\n",
    "        \"island\": \"Biscoe\",\n",
    "        \"culmen_length_mm\": 48.6,\n",
    "        \"culmen_depth_mm\": 16.0,\n",
    "        \"flipper_length_mm\": 230.0,\n",
    "        \"body_mass_g\": 5800.0,\n",
    "    },{\n",
    "        \"island\": \"Dream\",\n",
    "        \"culmen_length_mm\": 43.2,\n",
    "        \"culmen_depth_mm\": 17.5,\n",
    "        \"flipper_length_mm\": 175.0,\n",
    "        \"body_mass_g\": 3500.0,\n",
    "    },{\n",
    "        \"island\": \"Torgersen\",\n",
    "        \"culmen_length_mm\": 38.6,\n",
    "        \"culmen_depth_mm\": 16.0,\n",
    "        \"flipper_length_mm\": 176.0,\n",
    "        \"body_mass_g\": 3700.0,\n",
    "    }]\n",
    "\n",
    "predictor = Predictor(\"penguins-endpoint\")\n",
    "inference_response = predictor.predict(data=json.dumps(payload))\n",
    "print (inference_response)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "penguins",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
